\chapter{TELAAH PUSTAKA}
\label{cha:2-TelaahPustaka}

\vspace{1cm}
\section{\textit{Computer Vision}}
\hspace{1,2cm}\textit{Computer Vision} atau visi komputer adalah bidang kecerdasan buatan (AI) yang memungkinkan komputer dan sistem memperoleh informasi bermakna dari gambar digital, video, dan input visual lainnya, dan mengambil tindakan atau membuat rekomendasi berdasarkan informasi tersebut. Jika kecerdasan buatan memungkinkan komputer untuk berpikir, visi komputer memungkinkan untuk melihat, mengamati, dan memahami (IBM, 2020).

\textit{Computer vision} bekerja hamper sama dengan visi manusia, kecuali manusia memiliki permulaan. Penglihatan manusia memiliki keunggulan konteks seumur hidup untuk melatih cara membedakan objek, seberapa jauh jaraknya, apakah bergerak, dan apakah ada yang salah dalam sebuah gambar. \textit{Computer vision} melatih mesin untuk melakukan fungsi-fungsi melatih mesin untuk melakukan fungsi-fungsi ini, tetapi ia harus melakukannya dalam waktu yang jauh lebih singkat dengan kamera, data, dan algoritma daripada retina, saraf, optic, dan korteks visual karena sistem yang dilatih untuk memeriksa produk atau mengamati asset produksi dapat menganalisis ribuan produk atau proses dalam satu menit, memperhatikan cacat atau masalah yang tidak terlihat, sistem tersebut dapat dengan cepat melampaui kemampuan manusia. 

Memahami dan menentukan tugas visi komputer tertentu dapat memfokuskan dan memvalidasi proyek dan aplikasi, serta mempermudah untuk memulai. Hal dasar untuk \textit{computer vision} adalah \textit{object detection}, beberapa tugas visi komputer lainnya, seperti \textit{image classification, object detection, object tracking}, dan \textit{content-based image retrieval} (U. Arshad, 2021).

\vspace{1cm}
\section{Pengertian Citra}
Citra didefinisikan sebagai fungsi dari dua variabel misalnya \textit{a(x,y)} dimana a sendiri sebagai amplitudo (misalnya kecerahan) citra pada koordinat (x,y) (I. T. Young et al, 1995). Citra digital a[m,n] merupakan citra dalam ruang diskrit 2D yang berasal dari citra analog a(x,y) di ruang kontinyu 2D melalui proses sampling yaitu yang biasa disebut sebagai digitalisasi. Sedangkan, menurut Maria citra digital adalah citra f(x,y) yang telah didiskritkan oleh pada koordinat spasial dan kecerahan. Citra digital direpresentasikan oleh \textit{array} dua dimensi atau sekumpulan \textit{array} dua dimensi dimana setiap \textit{array} merepresentasikan satu kanal warna. Nilai kecerahan yang didigitalkan dinamakan nilai tingkat keabuan (A. McAndrew, 2004).

Setiap elemen \textit{array} tersebut dinamakan piksel yang diambil dari istilah \textit{picture element}. Dimensi citra biasanya ditulis dengan format panjang x tinggi (misalnya 640 x 480 piksel). Namun, perlu diperhatikan dengan seksama bahwa secara matematis, definisi citra terlihat seperti di bawah ini, dimana x menunjukkan baris dan y menunjukkan kolom:

\[
f(x,y)=
\begin{bmatrix}
	f\left(0,0\right)  & f\left(0,1\right) & ... & f\left(0,N-1\right) \\ 
	f\left(1,0\right)  & f\left(1,1\right) & ... & f\left(1,N-1\right) \\
	... & ... & ... & .. \\
	f\left(M-1,0\right) & f\left(M-1,1\right) & ... & \ f\left(M-1,N-1\right)
\end{bmatrix}
\]

Seperti pada layar monitor, koordinat citra dimulai dari pojok kiri atas. Secara matematis dimulai dari (0,0) dan berakhir di (M-1, N-1), dimana M menunjukkan tinggi, dan N menunjukkan panjang.

\section{Pengolahan Citra}
\hspace{1,2cm}Pengolahan citra adalah pemrosesan citra, khususnya menggunakan komputer menjadi citra yang kualitasnya lebih baik. Pengolahan citr adikembangkan bertujuan untuk (M. Petrou, 1999):
\begin{enumerate}
	\item Untuk memperbaiki tampilan citra (\textit{image enhancement}).
	\item Untuk mengurangi ukuran file citra dengan tetap mempertahankan kualitas citra (\textit{image compression}).
	\item Untuk memulihkan citra ke kondisi semula (\textit{image restoration}). 
	\item Untuk menyoroti ciri tertentu dari citra agar lebih mudah untuk di analisis. 
\end{enumerate}

Pengolahan citra adalah cabang ilmu informatika untuk memperbaiki kualitas citra agar kualitasnya lebih baik atau lebih mudah diinterpretasi oleh manusia maupun komputer. Input dari program pengolahan citra adalah citra dan outputnya pun citra pula.

Pengolahan citra digital digunakan dalam berbagai bidang untuk mempermudah manusia dalam melakukan analisis dan pekerjaan. Bentuk aplikasi pengolahan citra digital yang digunakan bidang militer, industry, medis, transportasi, hukum dan keamanan, pemetaan, robotika, fotografi, film, pencarian gambar berdasarkan kandungan citra, dan pemahaman kandungan citra. Salah satu pemanfaatan teknologi pengolahan citra digital yaitu bisa memahami maksud dari sebuah citra. Apabila aplikasi diberikan input berupa gambar yang mampu mendefinisikan bahwa dalam gambar tersebut terdapat gambar yang mendapati objek, seperti kendaraan, jalan, buah, dan lainnya.

\section{\textit{Artificial Intelligence} (AI)}
\hspace{1,2cm}\textit{Artificial inlelligence} atau kecerdasan buatan adalah studi tentang teori dan pengembangan sistem komputer agar mampu melakukan tugas-tugas yang dahulu hanya dapat dilakukan oleh manusia. Seperti membadakan berbagai gambar, menjawab pertanyaan, mengenali dan menerjemahkan bahasa, dan sebagainya (R. Primartha, 2018). 

Komputer atau mesin cukup bagus untuk melakukan hal-hal berikut: menyelesaikan perhitungan aritmatika dengan cepat, mengerjakan secara akurat apa-apa yang sudah deprogram oleh komputer. Namun, komputer atau mesin memiliki kelemahan, seperti sulit berinteraksi dengan \textit{noisy data} (data yang blur/bias), sulit memahami lingkungan, kurang toleran yerhadap kesalahan (\textit{fault tolerance}), sulit beradaptasi dengan situasi dan kondisi tertentu. Untuk mengatasi hal tersebut ada lima hal yang perlu dimiliki oleh mesin, yaitu:

\begin{enumerate}
	\item Persepsi
	
	Terkait dengen permasalahan pengindraan. Mesin harus memiliki indra untuk dapat mengenali dunia sekitarnya.
	
	\item Pemrosesan bahasa alami (NLP)
	
	Kemampuan untuk mengidentifikasi kalimat dan memahami perbedaan aksesn dan maknanya.
	
	\item Menyampaikan pengetahuan
	
	Menyampaikan berbagai informasi di dunia luar berdasarkan pemikirannya sendiri.
	
	\item Pengambilan keputusan
	
	Mampu memecahkan berbagai permasalahan secara logis.
	
	\item Perencanaan dan pemetaan
	
	Memetakan dunia tiga dimensi dan merencanakan rute paling efektif.
	Salah satu bagian penting dari AI adalah machine learning atau pembelajaran 
\end{enumerate}

Salah satu bagian penting dari AI adalah \textit{machine learning} atau pembelajaran mesin, yaitu dicirikan sebagai studi tentang algoritma dan model statistik yang digunakan sistem komputer untuk belajar dari data sampel dan pengalaman sebelumnya tanpa diprogram secara eksplisit untuk mencapai tugas tertentu. Dengan kemampuan untuk mengidentifikasi pola yang tidak jelas dalam data, kita dapat menggunakan pembelajaran mesin untuk memecahkan banyak masalah, termasuk menilai hubungan dua variabel, membuat prediksi berdasarkan karakteristik dasar, mengidentifikasi objek dengan pola yang sebanding, dan menggabungkan subjek dengan kriteria tertentu. Baik \textit{Artificial Intelligence}, \textit{Machine Learning}, dan \textit{Deep Learning} merupakan tiga istilah yang popular, namun banyak yang salah mengira bahwa ketiganya menggambarkan hal yang sama, padahal tiga hal yang berbeda. Bagaimana hubungan tiga istilah ini, seperti pada Gambar \ref{img:Hubungan-Artificial-Intelligence}

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture1.jpg}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{(a) Hubungan Artificial Intelligence, Machine Learning, dan Deep Learning. (b) Jenis Machine Learning\\(Sumber: C. Thongprayoon et al, 2020)}\label{img:Hubungan-Artificial-Intelligence}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Disamping hal tersebut, \textit{artificial intelligence} (AI) memungkinkan untuk berfikir, dan salah satu bagian dari \textit{artificial intelligence} untuk dapat melihat, mengamati, dan memahami adalah komputer visi atau \textit{computer vision}. \textit{Computer vision} memungkinkan untuk komputer dan sistem memberikan informasi berarti dari gambar digital, dan visual input. 

\section{\textit{Object Detection}}
\hspace{1,2cm}\textit{Object detection} atau deteksi objek dianggap sebagai salah satu bidang penting dalam pembelajaran mendalam dan visi komputer. Deteksi objek telah ditentukan oleh banyak aplikasi dalam visi komputer, seperti pelacakan objek, pengambilan, dan pengawasan video. Deteksi objek adalah teknologi \textit{deep learning} dimana benda, manusia, bengunan, mobil, dapat dideteksi sebagai objek dalam gambar dan video (U. Arshad, 2021).

Deteksi objek untuk mengenali objek dengan kotak pembatas pada gambar, dimana dalam klasifikasi gambar, cukup mengkategorikan (mengklasifikasikan) objek pada gambar atau tidak dalam hal kemungkinan (\textit{probability}), seperti contoh pada Gambar \ref{img:Classification-Object-Detection}

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture2.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Classification, Object Detection dan Segmentation Representation\\(Sumber: A. Patel, 2020)}\label{img:Classification-Object-Detection}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Pada Gambar \ref{img:Segementation-Classification}, terlihat bahwa kucing (cat) dengan kotak pembatas dan tanpa kotak pembatas dapat membedakan mendasar antara klasifikasi citra dan deteksi objek.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture3.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Segmentation, Classification+Localization, Object Detection\\(Sumber: A. Patel, 2020)}\label{img:Segementation-Classification}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Dalam mempelajari deteksi objek, maka diperlukan mengetahui klasifikasi citra (\textit{image classification}). Ketika gambar adalah input ke CNN, masalah mengklasifikasikan kelas yang sesuai dengan gambar dikenal sebagai klasifikasi gambar, dan seperti yang ditunjukkan pada Gambar \ref{img:Image-Classification}, nilai probabilitas untuk semua kelas yang ditargetkan adalah keluaran.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture4.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Image Classification\\(Sumber: A. Patel, 2020)}\label{img:Image-Classification}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Dapat juga dianggap bahwa deteksi objek sebagai masalah dimana tugas klasifikasi gambar memiliki tugas regresi yang memprediksi posisi objek menggunakan \textit{bounding box} (kotak pembatas) pada Gambar \ref{img:Object-Bounding-Box}. 

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture5.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Object Detection dengan Bounding Box\\(Sumber: A. Patel, 2020)}\label{img:Object-Bounding-Box}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Masalah deteksi objek mengasumsikan bahwa beberapa kelas objek mungkin ada dalam gambar pada waktu yang sama. Dapat memvisualisasikan seperti dua jenis masalah, 1) klasifikasi multi label (beberapa kelas dalam satu gambar), 2) Bounding Box (masalah regresi) dimana harus memprediksi nilai koordinat kotak pembatas (\textit{bounding box}) dalam bentuk x, y, w, h.

Dalam deteksi objek, terdapat \textit{object localization} atau lokalisasi objek yang merupakan untuk memprediksi objek dalam sebuah citra serta batas-batasnya. Perbedaan antara lokalisasi objek dan deteksi objek tidak kentara. Sederhananya, lokalisasi objek bertujuan untuk menemukan objek utama (atau yang paling terlihat) dalam sebuah gambar, sedangkan deteksi objek mencoba untuk mengetahui semua objek dan batasannya.

Suatu klasifikasi citra atau model pengenalan citra hanya mendeteksi probabilitas suatu objek dalam suatu citra. Berbeda dengan ini, lokalisasi objek mengacu pada mengidentifikasi lokasi suatu objek dalam gambar. Algoritma lokalisasi objek akan menampilkan koordinat lokasi objek sehubungan dengan gambar. Dalam visi komputer, cara paling popular untuk melokalkan objek dalam gambar adalah dengan merepresentasikan lokasinya dengan bantuan kotak pembatas (\textit{bounding box}).

Bounding box dapat diinisialisasi menggunakan parameter berikut: 
\begin{itemize}
	\item bx, by: koordinat pusat kotak pembatas (center of bounding box)
	\item bw: lebar kotak pembatas dengan lebar gambar (width)
	\item bh: tinggi kotak pembatas dengan tinggi gambar (height)
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture6.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Intersection Over Union (IoU)\\(Sumber: A. Patel, 2020)}\label{img:Intersection-Over-Union}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Dengan memprediksi ini, dapat menghitung Mean-IoU dan memprediksi kotak pembatas (\textit{bounding box}) yang melokalkan objek di gambar.
\begin{itemize}
	\item IoU adalah Intersection-Over-Union (IoU) disebut sebagai Indeks Jaccard (\textit{Jaccard Index}) dianggap sebagai salah satu metrik kinerja yang paling banyak digunakan dalam deteksi objek. 

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.4\columnwidth]{bab2/Gambar/Picture7.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Persamaan IoU\\(Sumber: A. Patel, 2020)}\label{img:Persamaan-IOU}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\item IoU adalah area tumpang tindih (\textit{overlap}) antara segmentasi yang diprediksi (\textit{prediction}) dan kebenaran dasar (\textit{ground truth}), seperti yang ditampilkan pada Gambar \ref{img:Persamaan-IOU}. Metrik ini bervariasi dari 0-1 (0-100\%) dengan 0 menyiratkan tidak ada tumpeng tindih (sampah) dan 1 menandakan segmentasi yang tumpang tindih sempurna (\textit{fat dub}).
	
	\item Mean IoU adalah segmentasi biner (dua kelas) atau multi-kelas, mean Io Udari gambar dihitung dengan mengambil IoU dari setiap kelas dan merata-ratakannya. 

\end{itemize}

\section{Machine Learning}
\hspace{1,2cm}Istilah \textit{machine learning} mula-mula diperkenalkan oleh Arthur Samuel pada tahun 1959 melalui jurnalnya yang berjudul "Some Studies in Machine Learning Using the Game of Checkers". (IBM Journal of Research and Development). Samuel mencoba mengajari program komputer untuk bermain catur. Tujuannya adalah membuat agar komputer dapat bermain catur lebih baik dari dirinya. Pada tahun 1962 program buatannya dapat mengalahkan juara catur dari negara bagian Connecticut (R. Primartha, 2018).

\textit{Machine learning} membutuhkan sebuah model yang didefinisikan berdasar parameter-parameter tertentu. Proses learning adalah eksekusi program komputer untuk mengoptimasi parameter-parameter dari model tersebut, dengan memanfaatkan data training atau \textit{past experience}.

Jadi, secara sederhana dapat dijelaskan bahwa \textit{machine learning} adalah pemrograman komputer untuk mencapai kriteria/performa tertentu dengan menggunakan sekumpulan data training atau pengalaman di masa lalu (\textit{past experience}). \textit{Machine learning} mempelajari teori agar komputer mampu "belajar" dari data. 

Secara umum algoritma \textit{machine learning} dapat dikelompokkan menjadi lima bagian, yaitu \textit{supervised learning}, \textit{unsupervised learning}, \textit{semi-supervised learning}, \textit{reinforcement learning}, dan \textit{deep learning}.

\subsection{Supervised Learning} 
\hspace{1,2cm}Sebagian besar praktik machine learning mengandalkan algoritma \textit{supervised learning}. Algoritmanya dinamakan seperti ini karena training dataset (sekumpulan data untuk training) akan memandu dan mengajari komputer agar menghasilkan outcome sesuai harapan. Pada \textit{supervised learning} menggunakan sebuah algoritma untuk mempelajari mapping function antara input dengan output. Berbagai kemungkinan output sudah diketahui dan data-data yang digunakan untuk latihan (training) sudah diberi label dengan jawaban yang benar. \textit{Supervised learning} dapat bermanfaat untuk memprediksi sesuatu dengan bantuan training dataset. Berikut skema \textit{supervised learning} pada Gambar \ref{img:Skema-Supervised-Learning} (R. Primartha, 2018).

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture8.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Skema Supervised Learning\\(Sumber: M. Kozan, 2021)}\label{img:Skema-Supervised-Learning}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textit{Supervise learning} menggunakan training data yang sudah diberi label untuk mempelajari \textit{mapping function}, dari input variables (x) ke ouput variables (y).
\[y=f\ (x)\]

Sebagai contoh, sebuah algoritma klasifikasi akan dapat mengidentifikasi berbagai bentuk bangun setelah melalui proses belajar dari sekumpulan bangun datar yang sudah ditandai atau diberi label dengan ciri tertentu seperti pada gambar 2.12.

Permasalahan-permasalahan yang terkait dengan \textit{supervised learning} dapat dikategorikan menjadi dua jenis:
\begin{enumerate}
	\item \textit{Classification}
	
	Klasifikasi bertujuan untuk memprediksi outcome dari input (sample yang diberikan), dimana output variabel berbentuk kategori-kategori. Contoh: pria/wanita, sakit/sehat, tinggi/rendah, dan sebagainya.
	
	\item \textit{Regression}
	
	Regression bertujuan untuk memprediksi outcome dari input (sample yang diberikan), dimana output, variabel berbentuk nilai aktual (\textit{real values}). Contoh: prediksi harga rumah, tinggi badan seseorang, curah hujan, dan sebagainya. 
	
\end{enumerate}

Ada beberapa algoritma yang sudah dikembangkan dan terkait dengan \textit{supervised learning}, diantaranya:
\begin{enumerate}
	\item Decision tree,
	\item Naïve Bayes Classifier,
	\item Artificial Neural Network,
	\item Support Vector Machine,
	\item Linear Regression,
	\item Logistic Regression,
	\item CART,
	\item KNN (-KNearest Neighbor), dsb.
\end{enumerate}

\subsection{Unsupervised Learning}
\hspace{1,2cm}Berbeda dengan supervised learning, pada \textit{unsupervised learning} persoalan diproses hanya mengandalkan data yang belum dilatih sebelumnya. \textit{Unsepervised learning} menggunakan \textit{unlabeled training dataset} untuk memodelkan struktur dari data, sehingga unsupervised learning bersifat lebih subjektif dibandingkan \textit{supervised learning}. Berikut skema \textit{unsupervised learning} pada Gambar \ref{img:Skema-Unsupervised-Learning} (R. Primartha, 2018).

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture9.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Skema Unsupervised Learning\\(Sumber: M. Kozan, 2021)}\label{img:Skema-Unsupervised-Learning}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textit{Unsupervised learning} bermanfaat untuk kasus-kasus dimana kita ingin menemukan relasi implisit (implicit relationships) dari \textit{unlabeled dataset} yang disediakan. Jadi, pada \textit{unsupervised learning} kita tidak memprediksi masa depan, sebab input variable (X) tidak memiliki relasi dengan output variabel (Y). 
\[ f(x) \]

Untuk memudahkan memahaminya, dapat diasumsikan saat ini belum pernah membeli majalah sama sekali. Suatu ketika membeli beberapa buah majalah dan ingin membaginya menjadi beberapa kategori, dengan tujuan agar nantinya mudah dicari. Maka, dapat dimulai dengan mengidentifikasi majalah-majalah berdasarkan kemiripan. Misalnya, berdasarkan isi, penerbit, dan lain-lain yang bisa ditentukan sesuai kebutuhan.

Permasalahan seputar \textit{unsupervised learning} dapat dikelompokkan menjadi tiga kategori, yaitu:

\begin{enumerate}
	\item Association
	
	Association bertujuan untuk menemukan peluang (probabilitas) berdasarkan keterkaitan (co-occurrence) dari item-item dalam sebuah kumpulan. Sebuah contoh, jika customer membeli teh celup, maka kemungkinan besar (sekitar 80%) customer juga membeli gula pasir. Association banyak digunakan dalam market-basket analisis. 
	\item Clustering
	
	Clustering bertujuan untuk mengelompokkan sample dalam cluster yang sama berdasarkan kemiripan (similiarity).
	
	\item Dimensionality Reduction
	
	Dimensionality Reduction berarti mengurangi sejumlah variabel dari dataset namun tetap memastikan informasi yang penting masih tersedia. Dimensionality Reduction dapat diwujudkan menggunakan metode:
	\begin{enumerate}[label=(\alph*)]
		\item Feature Extraction
		
		Melakukan transformasi data dari dimensi tinggi (a high-dimensional space) ke dimensi yang lebih rendah (a low-dimensional space).
		
		\item Feature Selection
		
		Memilih Sebagian saja (subset) dari variabel asal (original variabel). 
	\end{enumerate}
\end{enumerate}

Beberapa algoritma yang dikelompokkan dalam \textit{unsupervised learning}, antara lain: 
\begin{enumerate}
	\item K-Means
	\item Hierarchical Clustering
	\item DBSCAN
	\item Fuzzy C-Means
	\item Self-Orginizing Map, dan sebagainya.	
	
\end{enumerate}

\subsection{Semi-supervised learning}
\hspace{1,2cm}Metode ini berada diantara yang \textit{supervised} dan \textit{unsupervised learning} di mana memiliki sejumlah besar masukan data, beberapa di antaranya diberi label dan sisanya tidak. Banyak masalah pembelajaran kehidupan nyata termasuk dalam bidang pembelajaran mesin ini. Alasannya adalah \textit{semi-supervised} membutuhkan lebih sedikit intervensi manusia karena menggunakan data berlabel dalam jumlah yang sangat kecil dan data yang tidak berlabel dalam jumlah besar. Memanfaatkan kumpulan data yang kurang berlabel lebih menarik karena kumpulan data tersebut sangat sulit untuk dikumpulkan serta mahal dan mungkin memerlukan akses ke pakar domain. Dataset yang tidak berlabel di sisi lain lebih murah dan lebih mudah diakses (X. Zhu, 2018).

Kedua teknik pembelajaran \textit{supervised} dan \textit{unsupervised learning} bisa digunakan untuk melatih algoritma pembelajaran dalam pembelajaran \textit{semi-supervised}. Teknik \textit{unsupervised learning} dapat digunakan untuk mengungkap struktur dan pola tersembunyi dalam kumpulan data input. Sedangkan teknik supervised learning dapat digunakan untuk membuat prediksi tebakan pada data yang tidak berlabel, memasukkan data kembali ke algoritma pembelajaran sebagai data pelatihan, dan menggunakan pengetahuan yang diperoleh untuk membuat prediksi pada kumpulan data baru. Dengan demikian, dapat mengatakan bahwa data yang tidak berlabel digunakan untuk memodifikasi atau memprioritaskan kembali prediksi atau hipotesis yang diperoleh dari data yang berlabel. Gambar \ref{img:Skema-Semi-Supervised-Learning} mengilustrasikan berbagai tahapan metode \textit{semi-supervised learning}.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture10.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{Skema Semi-Supervised Learning\\(Sumber: A. B. Nassif et al, 2019)}\label{img:Skema-Semi-Supervised-Learning}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Untuk memanfaatkan data pelatihan yang tidak berlabel, semua algoritma \textit{semi-supervised learning} melakukan setidaknya satu dari asumsi berikut asumsi kehalusan, asumsi cluster, dan asumsi manifold.

\subsection{Reinforcement Learning}
\hspace{1,2cm}\textit{Reinforcement learning} merupakan metode pembelajaran yang dipengaruhi oleh feedback dari lingkungan dengan Teknik pembelajaran yang iterative (berulang-ulang) dan adaptive (menyesuaikan). \textit{Reinforcement learning} dipercaya mendekati cara manusia belajar (R. Primartha, 2018). 

\textit{Reinforcement learning} (RL) diinspirasi oleh kebiasaan makhluk hidup dalam belajar dan bertindak, khususnya manusia. Pada RL tidak ada dataset. Data-data diperoleh berdasarkan pengalaman. Algoritma \textit{reinforcement learning} mengijinkan agent untuk memutuskan aksi selanjutnya berdasarkan kondisi saat ini (\textit{current state}). \textit{Reinforcement learning} kadang disebut juga \textit{credit assessment learning}, sebab learning difokuskan untuk memaksimalkan perolehan \textit{rewards}. \textit{Reinforcement learning} tergantung pada proses coba-coba untuk mengungkap rangkaian tindakan yang memaksimalkan metrik imbalan kumulatif, yang digunakan untuk membuat algoritma memahami apakah itu mengarah ke arah yang benar atau tidak. Berikut skema \textit{reinforcement learning} pada Gambar \ref{img:Skema-Reinforcement-Learning}. 

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture11.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{Skema Reinforcement Learning\\(Sumber: R. Sutton, 1998)}\label{img:Skema-Reinforcement-Learning}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Menurut R. Sutton, proses \textit{reinforcement learning} dapat dipresentasikan dalam matematika sebagai \textit{Markov Decision Process} (MDP), memperkenalkan 4 set {S, A, P, R}, dengan:\\
S - Kumpulan status tempat agen dapat berada, pada saat tertentu;\\
A - Serangkaian kemungkinan Tindakan yang dapat dilakukan agen dalam waktu tertentu;\\
P - Himpunan probabilitas, bahwa sebuah agen, yang berada dalam keadaan s, bertransisi ke keadaan s' dengan melakukan Tindakan A dalam waktu t+1;

Representasi \textit{reinforcement learning} mirip dengan supervised learning. Yang membedakan adalah pada reinforcement learning tidak hanya x, namun x dan z.
\[ y=\ f\ \left(x\right)\ given\ z \]

Tidak seperti \textit{supervised} dan \textit{unsupervised learning} dimana algoritma sudah memiliki tujuan (goal). Algoritma \textit{reinforcement learning} tidak memiliki tujuan eksplisit, sebagai gantinya algoritma dipaksa untuk belajar menemukan nilai optimal melalui kegiatan trial dan error.

\textit{Reinforcement learning} banyak diimplementasikan pada \textit{game theory, control theory, operation research, information theory, simulation-based optimaztion, multi-agent systems, swarm intelligence, statistics}, dan \textit{genetic algorithm}.

Contoh penerapan \textit{reinforcement learning} yaitu pada bidang robotic. Sebuah robot dapat belajar untuk menghindari tabrakan dengan cara menerima feedback negative manakala robot tersebut menabrak halangan tertentu. Robot akan dibiarkan berjalan tanpa dipandu. Robot akan belajar dari pengalaman sebelumnya untuk menemukan rute paling optimal. 

Beberapa algoritma yang dikelompokkan dalam \textit{reinforcement learning} antara lain:
\begin{enumerate}
	\item Genetic Algorithm (GA)
	\item Dynamic Programming (DP)
	\item Generalized Policy Iteration (GPI)
	\item Monte Carlo Methods
\end{enumerate}

\subsection{Deep Learning}
\hspace{1,2cm}\textit{Deep learning} merupakan metode pembelajaran yang memanfaatkan \textit{artificial neural networks} yang berlapis-lapis (multi layer). \textit{Artificial neural networks} ini dibuat mirip dengan otak manusia, di mana neuron-neuron terkoneksi satu sama lain, sehingga membentuk sebuah jaringan neuron yang sangat rumit (R. Primartha, 2018).

\textit{Deep learning} atau \textit{deep structured leaning} atau hierarchical learning atau deep neural merupakan metode pembelajaran yang memanfaatkan multiple non-linear transformation. \textit{Deep learning} dapat dipandang sebagai gabungan machine learning dengan \textit{artificial intelligence} (AI). \textit{Deep learning} pada hakekatnya merupakan perluasan atau pengembangan dari \textit{neural network} atau jaringan saraf tiruan (JST).

Jika dikembalikan kepada tujuan \textit{machine learning} semula, yaitu komputer yang dapat belajar (dari data atau pengalaman), maka \textit{deep learning} adalah apa yang selama ini dicari. \textit{Deep learning} menirukan cara berpikir manusia. Pada \textit{deep learning}, komputer harus memproses data yang sangat banyak, berlapis-lapis, dan output dari layer sebelumnya akan menjadi input bagi layer sesudahnya.

Struktur umum dan dasar dari skema \textit{deep learning} ditunjukkan pada Gambar \ref{img:Skema-Umum-Deep-Learning}. Ini terdiri dari lapisan masukan, yang merupakan data masukan ke algoritma; lapisan tersembunyi, di mana algoritma membuat banyak perhitungan matematis, dan lapisan output, yang merupakan hasil dari perhitungan algoritma.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture12.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{Skema Umum \textit{Deep Learning}\\(Sumber: A. Feizollah et al, 2022)}\label{img:Skema-Umum-Deep-Learning}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Sejarah \textit{deep learning} dimulai pada tahun 2006, yaitu setelah Geoffrey Hinton mempublikasikan paper yang memperkenalkan salah satu varian \textit{neural networks} yang disebut \textit{deep belief nets}. Paper ini merupakan awal kemunculan istilah \textit{deep learning}, untuk membedakan arsitektur \textit{neural network} konvensional (\textit{single layer}) dengan arsitektur neural network multi/banyak layer. Dengan kata lain, deep learning adalah salah satu cabang machine learning yang menggunakan \textit{deep neural network} untuk menyelesaikan permasalahan pada domain \textit{machine learning}. 

Pada tahun 2009, Andrew memperkenalkan penggunaan GPU untuk \textit{deep learning} melalui paper yang berjudul \textit{large-scale deep unsupervised learning using graphics processors}. Dengan menggunakan GPU, algoritma \textit{deep learning} dapat dijalankan lebih cepat disbanding dengan tanpa GPU (hanya menggunakan CPU), Perkembangan \textit{deep learning} maju pesat berkat keberadaan \textit{hardware} yang memadai. Dan saat ini, \textit{deep learning} sudah banyak diaplikasikan di berbagai area, seperti pengenal wajah, \textit{self-driving car}, pengenal suara, dan sebagainya. 

\textit{Deep learning} merupakan jalan untuk mencapai apa yang sudah dicita-citakan sebelumnya oleh manusia, yaitu kecerdasan buatan bagi mesin. Bentuk diagram \textit{network model deep learning} seperti pada Gambar \ref{img:Skema-Deep-Learning-Hidden-Layer}. Perhatikan bahwa \textit{hidden layer} hanya digambarkan tiga lapis saja, padahal kenyataanya bisa berjumlah sangat banyak, dapat diasumsikan seperti Gambar \ref{img:Skema-Deep-Learning-Hidden-Layer}.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture13.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{Skema \textit{Deep Learning} dengan Penambahan beberapa \textit{hidden layer}\\(Sumber: H. Kaur et al, 2021)}\label{img:Skema-Deep-Learning-Hidden-Layer}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Pada Gambar \ref{img:Skema-Deep-Learning-Hidden-Layer} mengandung 3 layer, yaitu input, \textit{hidden} dan output layer. Penambahan \textit{layer} ini terjadi pada \textit{hidden layer}. \textit{Hidden layer} pada skema \textit{deep learning} yang disebut dengan \textit{Multi Layer Peceptron} (MLP) disebabkan jumlah neuron semakin banyak dan itu artinya semakin banyak juga perhitungan yang harus dikerjakan pada setiap \textit{layer}. MLP merupakan pengembangan dari \textit{Single Layer Perceptron} (SLP) yang merupakan model paling sederhana dari neural network dan sekaligus merupakan dasar bagi model-model tingkat lanjut yang digunakan pada \textit{deep learning}. MLP kemudian menjadi cikal bakal metode \textit{deep learning} atau \textit{deep neural network} (DNN).

\textit{Deep learning} sudah dikembangkan ke berbagai model atau arsitektur yang berbeda-beda. Berikut daftar beberapa model atau arsitektur untuk \textit{deep learning}. 
\begin{enumerate}
	\item \textit{Recurrent Neural Networks} (RNN)
	\item \textit{Long Short-Term Memory} (LSTM)
	\item \textit{Convolutional Neural Network} (CNN)
	\item \textit{Deep Believe Networks} (DBN)
	\item \textit{Deep Stacking Networks} (DSN)
\end{enumerate}

Contoh penerapan masing-masing arsitektur deep learning dapat dipelajari pada Tabel \ref{tbl:Penerapan-Arsitektur-Deep-Learning}
%%%%%%%%%%%%%%%%%%%%%%%TABEL SEDERHANA%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{singlespace}
	\begin{table}[H]
		\centering
		\caption{Penerapan Arsitektur Deep Learning}
		\label{tbl:Penerapan-Arsitektur-Deep-Learning}
		\begin{adjustbox}{width=\columnwidth,center}
			\begin{tabular}{|c|c|l|}
				\hline
				No. & Arsitektur & \multicolumn{1}{c|}{Penerapan}                                                                                                                                           \\ \hline
				1   & RNN        & \textit{Speech recognition, handwriting recognition}                                                                                                                     \\ \hline
				2   & LSTM       & \textit{\begin{tabular}[c]{@{}l@{}}Natural language text compression, handwriting recognition,\\ speech recognition, gesture recognition, image captioning\end{tabular}} \\ \hline
				3   & CNN        & \textit{Image recognition, video analysis, natural language processing}                                                                                                  \\ \hline
				4   & DBN        & \textit{\begin{tabular}[c]{@{}l@{}}Image recognition, information retrieval, \\ natural language understanding, failure prediction\end{tabular}}                         \\ \hline
				5   & DSN        & \textit{Information retrieval, continuous speech recognition}                                                                                                            \\ \hline
			\end{tabular}
		\end{adjustbox}
	\end{table}
\end{singlespace}
%%%%%%%%%%%%%%%%%%%%%%%TABEL SEDERHANA%%%%%%%%%%%%%%%%%%%%%%%%%
Masing-masing arsitektur pada Tabel \ref{tbl:Penerapan-Arsitektur-Deep-Learning} memiliki perbedaan, berikut penjelasan dan diagram network beberapa arsitektur deep learning yang umum.

\subsubsection{Recurrent Neural Networks (RNN)}
\hspace{1,2cm}\textit{Recurrent Neural Network} (RNN) merupakan arsitektur \textit{deep learning} yang popular serta sangat menjanjinak untuk menyelesaikan berbagai persoalan yang terkait dengan \textit{Natural Language Processing} (NLP). Model RNN digunakan agar mesin dapat memahami bahasa manusia. Mulai dari cara berkomunikasi, mendengarkan, mengenali percakapan, hingga memahami tata bahasa dan aksen. RNN juga dapat diimplementasikan untuk mengenali gambar-gambar atau objek (R. Primartha, 2018).

Diagram network RNN seperti pada Gambar \ref{img:Diagram-RNN} berikut. 
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.8\columnwidth]{bab2/Gambar/Picture14.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{Diagram \textit{Recurent Neural Network} (RNN)\\(Sumber: K. Dass, 2020)}\label{img:Diagram-RNN}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Long Short Term Memory (LSTM)}
\hspace{1,2cm}\textit{Long Short Term Memory} (LSTM) merupakan building unit untuk \textit{layer-layer} pada recurrent neural network (RNN). LSTM mula-mula diusulkan oleh Sepp Hochreiter dan Jurgen Schmidhuber pada tahun 1997. LSTM juga banyak diimplementasikan pada bidang NLP. Boleh dibilang LSTM merupakan pengembangan dari RNN. Secara teoritis, jaringan saraf yang terhubung secara naif, yang disebut jaringan saraf berulang, dapat bekerja. Namun dalam praktiknya, mengalami dua masalah: gradien menghilang dan gradien meledak, yang membuatnya tidak dapat digunakan (R. Primartha, 2018).  Kemudian, LSTM ditemukan untuk mengatasi masalah ini dengan secara eksplisit memasukkan unit memori, yang disebut sel ke dalam jaringan. Ini adalah diagram blok bangunan LSTM pada Gambar \ref{img:Diagram-LSTM}.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.8\columnwidth]{bab2/Gambar/Picture15.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{Diagram \textit{Long Short Term Memory} (LSTM) \\(Sumber: S. Yan, 2016)}\label{img:Diagram-LSTM}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Convolutional Neural Network (CNN)}
\hspace{1,2cm}\textit{Convolutional Neural Networks} (CNN atau ConvNet) merupakan salah satu model deep learning yang banyak digunakan untuk keperluan analisis citra/visual. CNN adalah salah satu kategori utama untuk melakukan pengenalan dan klasifikasi gambar, deteksi objek, pengenalan wajah, dan sebagainya merupakan beberapa area dimana CNN banyak digunakan (R. Primartha, 2018).

Klasifikasi gambar CNN mengambil input gambar, memproses, dan mengklasifikasikannya dalam kategori tertentu, misalnya kucing, harimau, singa. Komputer melihat gambar input sebagai susunan piksel dan itu tergantung pada resolusi gambar. Berdasarkan resolusi gambar, akan terlihat h x w x d (h = Tinggi, w = Lebar, d = Dimensi). Misalnya, gambar array matriks RGB 6 x 6 x 3 (3 mengacu pada nilai RGB) dan gambar array matriks 4 x 4 x 1 dari gambar skala abu-abu, seperti pada Gambar \ref{img:Array-Matriks-RGB}.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.3\columnwidth]{bab2/Gambar/Picture16.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{Array dari Matriks RGB\\(Sumber: R. Prabhu, 2018)}\label{img:Array-Matriks-RGB}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Secara teknis, model \textit{deep learning} CNN untuk latih dan uji, setiap gambar input akan melewati serangkaian lapisan konvolusi dengan filter (Kernel), Pooling, \textit{fully connected layers} (FC) dan menerapkan fungsi softmax untuk mengklasifikasikan objek dengan nilai probabilistic antara 0 dan 1. Gambar 2.17. adalah alur dari CNN untuk memproses gambar input dan mengklasifikasikan objek berdasarkan nilai.


%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture17.jpg}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{Neural Network dengan banyak Convolusi Layer\\(Sumber: R. Prabhu, 2018)}\label{img:Neural-Network-Dengan-Banyak-Convolusi-Layer}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{enumerate}
	\item \textit{Convolution Layer}
	
	Konvolusi adalah lapisan pertama untuk mengekstraksi fitur dari gambar masukan. Konvolusi mempertahankan hubungan antara piksel dengan mempelajari fitur gambar menggunakan kotak kecil data masukan. Ini adalah operasi matematika yang mengambil dua input, seperti matriks gambar dan filter atau kernel.
	
	\begin{itemize}
		\item Sebuah gambar matriks (volume) dari dimensi \textbf{(h x w x d)}
		\item Sebuah filter \textbf{(fh x fw x d)}
		\item Output volume dimensi \textbf{(h - fh + 1) x (w - fw + 1) x 1 }
		
		%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		\begin{figure}[H]
			\vspace{-0.1cm}
			%\rule{\columnwidth}{0.1pt}
			\begin{center}
				\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture18.png}
			\end{center}
			\vspace{-0.2cm}
			%\rule{\columnwidth}{0.1pt}
			\captionsetup{justification=centering}
			\caption{Gambar Matriks Multiplies Kernel atau Filter Matriks\\(Sumber: R. Prabhu, 2018)}\label{img:Matriks-Multiplies}
		\end{figure}
		%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\end{itemize}
	Pertimbangkan gambar 5 x 5 yang nilai piksel gambarnya adalah 0, 1 dan matriks filter 3 x 3, seperti pada Gambar \ref{img:Matriks5x5}.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.7\columnwidth]{bab2/Gambar/Picture19.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Gambar matriks 5 x 5 dikalikan dengan Filter matiks 3 x 3}\label{img:Matriks5x5}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
	
	Kemudian, konvolusi matriks gambar 5 x 5 dikalikan dengan filter matriks 3 x 3 yang disebut "Feature Map" sebagai output yang ditunjukkan pada Gambar \ref{img:Output-Matriks-3-3}.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.7\columnwidth]{bab2/Gambar/Picture20.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Output Matriks 3 x 3}\label{img:Output-Matriks-3-3}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	Konvolusi gambar dengan filter berbeda dapat melakukan operasi seperti deteksi tepi, mengaburkan, dan memeprtajam dengan menerapkan filter. Berikut ini contoh yang menunjukkan berbagai gambar konvolusi setelah menerapkan berbagai jenis filter (Kernel) pada Gambar \ref{img:Fitur-Umum}.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.6\columnwidth]{bab2/Gambar/Picture21.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Beberapa Filter Umum\\(Sumber: R. Prabhu, 2018)}\label{img:Fitur-Umum}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\item Strides
	
	Stride adalah jumlah piksel yang bergeser di atas matriks input. Saat langkahnya 1, maka memindahkan filter ke 1 piksel sekaligus. Saat langkahnya 2, maka memindahkan filter ke 2 piksel sekaligus dan seterusnya. Gambar \ref{img:Stride-2-Piksel} menunjukkan konvolusi akan bekerja dengan Langkah 2.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.6\columnwidth]{bab2/Gambar/Picture22.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Stride 2 Piksel\\(Sumber: R. Prabhu, 2018)}\label{img:Stride-2-Piksel}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\item Padding
	
	Pada saat penggunaan filter, terkadang filter tidak pas dengan gambar masukan. Maka, terdapat dua pilihan: 
	\begin{itemize}
		\item Memadatkan gambar dengan angka nol (\textit{zero padding}) agar pas; 
		\item Menghilangkan bagian gambar yang tidak sesuai dengan filter. Ini disebut dengan \textit{valid padding} yang hanya menyimpan bagian gambar yang valid. 
		
	\end{itemize}
	
	\item Non Linerarity (ReLU)
	
	ReLU adalah singkatan dari \textit{Rectified Linear Unit} untuk operasi non-linear. Outputnya adalah \textit{f(x) = maks(0,x)}. ReLU penting karena tujuan ReLU adalah untuk mengenalkan non-linearitas di ConvNet, karena data dunia nyata ingin ConvNet pelajari adalah nilai linier non-negatif. Fungsi ini hanya mengembalikan nilai 0 jika nilai tersebut bernilai negative, selain itu mengembalikan nilai yang sama dengan yang diberikan, tidak lain adalah menghilangkan keluaran negative dan mempertahankan nilai antara 0 hingga + tak terhingga, seperti pada Gambar \ref{img:Operasi-RELU}. 
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.3\columnwidth]{bab2/Gambar/Picture23.1.png}\\
			\includegraphics[width=0.6\columnwidth]{bab2/Gambar/Picture23.2.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Operasi ReLU\\(Sumber: P. Ratan, 2021)}\label{img:Operasi-RELU}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\item Pooling Layer
	
	Bagian layer pooling akan mengurangi jumlah parameter ketika gambar terlalu besar. Penyatuan spasial juga disebut subsampling atau downsampling yang mengurangi dimensi setiap peta tetapi tetap mempertahankan informasi penting. Penyatuan spasial dapat dari berbagai jenis, diantaranya Max Pooling, Average Pooling, dan Sum Pooling.\\
	Max Pooling mengambil elemen tersbesar dari peta fitur yang diperbaiki. Mengambil elemen terbesar juga bisa mengambil pooling rata-rata. Jumlah semua elemen dalam peta fitur disebut sebagai kumpulan jumlah.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.5\columnwidth]{bab2/Gambar/Picture24.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Max Pooling}\label{img:Max-Polling}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\item Fully Connected Layer

	Lapisan yang disebut \textit{Fully Connected Layer}, diratakan matriks menjadi vector dan memasukkannya ke dalam \textit{fully connected layer}, seperti jaringan saraf (\textit{neural network}), seperti Gambar \ref{img:Setelah-Pooling-Layer}.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.5\columnwidth]{bab2/Gambar/Picture25.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Setelah Pooling Layer Diratakan sebagai FC Layer}\label{img:Setelah-Pooling-Layer}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	Pada Gambar \ref{img:Setelah-Pooling-Layer}, matriks peta fitur akan diubah menjadi vector (x1, x2, x3, ...). Dengan lapisan yang terhubung sepenuhnya, digabungkan fitur ini bersama untuk membuat model. Setelah itu, akhirnya memiliki fungsi aktivasi seperti softmax atau sigmoid untuk mengklasifikasikan keluaran sebagai objek, misalnya rumah, pohon, kucing, mobil, truk, dan sebagainya, seperti pada Gambar \ref{img:Arsitektur-CNN-Lengkap}.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.5\columnwidth]{bab2/Gambar/Picture26.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Arsitektur CNN Lengkap}\label{img:Arsitektur-CNN-Lengkap}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
\end{enumerate}

\subsubsection{Deep Believe Networks (DBN)}
\hspace{1,2cm}\textit{Deep Belief Neworks} (DBN) merupakan model \textit{deep learning} yang memanfaatkan tumpukan/\textit{stack Restricted Boltzmann Machines} (RBM) atau kadangkala \textit{Autoencoders}. \textit{Autoencoders} adalah model \textit{neural networks} yang memiliki input dan output yang sama. \textit{Autoencoder} mempelajari data input dan berusaha untuk melakukan rekonstruksi terhadap data input tersebut (R. Primartha, 2018).  Skema diagram DBN seperti pada Gambar \ref{img:Skema-Diagram-DBN}.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.6\columnwidth]{bab2/Gambar/Picture27.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{Skema Diagram DBN\\(Sumber: H. Liu {\&} B. Lang, 2019)}\label{img:Skema-Diagram-DBN}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Deep Stacking Networks (DSN)}
\hspace{1,2cm}Salah satu masalah pada \textit{deep learning} adalah proses learning sangat sulit dilakukan dan memerlukan komputasi yang cukup kompleks. Pada tahun 2011 Deng Yu mengusulkan model \textit{Deep Convex Networks} (DCN) atau \textit{Deep Stacking Network} (DSN), yang sedikit berbeda dibandingkan model \textit{deep learning} lain (R. Primartha, 2018). Secara umum model DSN terdiri atas ub-nets berukuran kecil dengan hanya sebuah hidden layer, seperti pada Gambar \ref{img:Skema-Diagram-DSN}.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.4\columnwidth]{bab2/Gambar/Picture28.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{Skema Diagram DSN\\(Sumber: L. Deng et al, 2012)}\label{img:Skema-Diagram-DSN}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Model \textit{deep learning} yang popular lainny aiatu Region Based CNN, Google Net, Generative Adversarial Network (GAN), dan You Only Look Once (YOLO).

\section{You Only Look Once (YOLO)}
\hspace{1,2cm}\textit{You Only Look Once} (YOLO) adalah algoritma deteksi objek real-time yang diperkenalkan pada tahun 2015 oleh Joseph Redmon, Santosh Divvala, Rosh Girshick dan Ali Farhadi dalam paper dengan judul "You Only Look Once: Unified, Real-Time Object Detection" (J. Redmon et al., 2015). Penulis membingkai masalah deteksi objek sebagai masalah regresi tugas klasifikasi dengan memisahkan kotak pembatas (\textit{bounding box}) secara spasial dan menghubungkan probabilitas ke masing-masing gambar yang terdeteksi menggunakan \textit{convolutional neural network} (CNN). YOLO adalah \textit{Convolutional Neural Network} (CNN) untuk melakukan deteksi objek secara real-time (V. Meel, 2022) (G. Boesch, 2022).

Beberapa alasan mengapa YOLO baik digunakan untuk deteksi objek real-time, diantaranya:
\begin{enumerate}
	\item Kecepatan (\textit{speed})
	
	YOLO sangat cepat karena tidak berurusan dengan jalur pipa (\textit{pipelines}) yang rumit. YOLO dapat memproses gambar pada 45 frames per second (FPS). Selain itu, YOLO mencapai rata-rata presisi atau mean average precision (mAP) lebih dari dua kali dibandingkan dengan sistem real-time lainnya, yang menjadikannya kandidat yang bagus untuk pemrosesan real-time. Dari grafik pada Gambar \ref{img:Kecepatan-YOLO} diamati bahwa YOLO jauh melampaui pendeteksi objek lainnya dengan 91 FPS.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.4\columnwidth]{bab2/Gambar/Picture29.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Kecepatan YOLO dibandingkan dengan detector Objek Lainnya\\(Sumber: S. A. S. Hernandez et al, 2020)}\label{img:Kecepatan-YOLO}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\item Akurasi deteksi tinggi (\textit{high detection accuracy})
	
	YOLO jauh melampaui model \textit{state-of-the-art} dalam akurasi dengan sedikit kesalahan latar belakang. 
	
	\item Generalisasi yang bagus (\textit{good generalization})
	
	YOLO mendorong sedikit lebih jauh dengan memberikan generalisasi yang lebih baik untuk domain baru, yang menjadikannya bagus untuk aplikasi yang mengandalkan deteksi objek yang cepat dan kuat. 
	
	\item Sumber terbuka (\textit{open-source})
	
	Membuat YOLO open-source membuat komunitas terus meningkatkan model. Inilah salah satu alasan mengapa YOLO telah melakukan begitu banyak perbaikan dalam waktu yang begitu terbatas. 
	
\end{enumerate}

\subsection{Arsitektur YOLO}
\hspace{1,2cm}Arsitektur YOLO memiliki keseluruhan 24 lapisan konvolusional, empat lapisan penyatuan maksimum, dan dua lapisan yang terhubung sepenuhnya, arsitektur YOLO secara umum pada Gambar \ref{img:Arsitektur-YOLO}.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture30.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{Arsitektur YOLO dari \textit{Original Paper}\\(J. Redmon et al., 2015)}\label{img:Arsitektur-YOLO}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Arsitektur YOLO bekerja sebagai berikut: 
\begin{itemize}
	\item Mengubah ukuran gambar input menjadi 448x448 sebelum melalui \textit{convolutional network}. 
	
	\item Konvolusi 1x1 pertama kali diterapkan untuk mengurangi jumlah saluran, yang kemudian diikuti oleh konvolusi 3x3 untuk menghasilkan output kuboid. 
	
	\item Fungsi aktivasi ReLU, kecuali lapisan terakhir, yang menggunakan fungsi aktivasi linier.
	
	\item Beberapa Teknik tambahan, seperti normalisasi batch dan droput, masing-masing mengatur model dan mencegah overfitting. 
\end{itemize}

\subsection{Cara kerja Deteksi Objek YOLO}
\hspace{1,2cm}Berikut ini adalah proses bagaimana YOLO melakukan deteksi objek untuk mendapatkan gambar (b) dari gambar (a) pada Gambar \ref{img:Cara-Kerja-YOLO}.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.9\columnwidth]{bab2/Gambar/Picture31.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{(A) Input Image dan (B) Hasil Algoritma YOLO\\(Sumber: Z. Kelta, 2022)}\label{img:Cara-Kerja-YOLO}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Algoritma YOLO bekerja berdasarkan empat pendekatan, sebagai berikut:
\begin{enumerate}[label=(\alph*)]
	\item \textit{Residual Blocks}(Blok Sisa)
	
	Langkah pertama dimulai dengan membagi gambar asli (A) menjadi sel grid (NxN) dengan bentuk yang sama, di mana N dalam hal ini adalah 4x4 grid sel pada Gambar \ref{img:Residual-Blocks}. Setiap sel dalam grid bertanggung jawab untuk melokalkan dan memprediksi kelas objek yang dicakupnya, bersama dengan nilai probabilitas/kepercayaan.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.9\columnwidth]{bab2/Gambar/Picture32.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Residual Blocks\\(Sumber: Z. Kelta, 2022)}\label{img:Residual-Blocks}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\item \textit{Bounding Box Regression} (Regresi Kotak Pembatas)
	
	Langkah selanjutnya adalah menentukan kotak pembatas (\textit{bounding box}) yang sesuai dengan persegi Panjang yang menyoroti semua objek dalam gambar. Dapat memiliki kotak pembatas sebanyak objek di dalam gambar yang diberikan. YOLO menentukan atribut kotak pembatas ini menggunakan modul regresi tunggal dalam format berikut, dimana Y adalah representasi vector terakhir untuk setiap kotak pembatas.\\
	Y = [pc, bx, by, bh, bw, c1, c2]\\
	Ini sangat penting selama fase pelatihan model.
	\begin{itemize}
		\item pc sesuai dengan skor probabilitas dari grid yang berisi objek. Misalnya, semua grid yang berwarna merah akan memiliki skor probabilitas lebih tinggi dari nol. Gambar \ref{img:Grid-Probabilitas} adalah versi yang disederhanakan karena probabilitas setiap sel kuning adalah nol (tidak signifikan)
		
		%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		\begin{figure}[H]
			\vspace{-0.1cm}
			%\rule{\columnwidth}{0.1pt}
			\begin{center}
				\includegraphics[width=0.9\columnwidth]{bab2/Gambar/Picture33.png}
			\end{center}
			\vspace{-0.2cm}
			%\rule{\columnwidth}{0.1pt}
			\captionsetup{justification=centering}
			\caption{Grid dengan Probabilitas\\(Sumber: Z. Kelta, 2022)}\label{img:Grid-Probabilitas}
		\end{figure}
		%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		
		\item bx dan by adalah koordinat x dan y dari pusat kotak pembatas (\textit{center of bounding box}) sehubungan dengan grid sel pembungkus. 
		
		\item bh dan bw sesuai dengan tinggi dan lebar kotak pembatas sehubungan dengan sel grid pembungkus
		
		\item c1 dan c2 sesuai dengan dua kelas Player dan Ball, dapat memiliki kelas sebanyak yang dibutuhkan oleh pengguna.
		
		Untuk dapat memahami dan terlihat, seperti pada Gambar \ref{img:Cara-Bounding-Box} berikut.
		%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		\begin{figure}[H]
			\vspace{-0.1cm}
			%\rule{\columnwidth}{0.1pt}
			\begin{center}
				\includegraphics[width=0.9\columnwidth]{bab2/Gambar/Picture34.png}
			\end{center}
			\vspace{-0.2cm}
			%\rule{\columnwidth}{0.1pt}
			\captionsetup{justification=centering}
			\caption{Cara \textit{Bounding Box}\\(Sumber: Z. Kelta, 2022)}\label{img:Cara-Bounding-Box}
		\end{figure}
		%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\end{itemize}
	
	\item \textit{Intersection Over Unions} (IOU)
	
	Sebagian besar waktu, satu objek dalam gambar dapat memiliki beberapa kandidat kotak petak untuk prediksi, meskipun tidak semuanya relevan. Tujuan dari IOU (nilai antara 0 dan 1) adalah untuk membuang kotak kisi tersebut agar hanya menyimpan yang relevan. Inilah logika dari IOU:
	
	\begin{itemize}
		\item Pengguna menentukan ambang pemilihan IOU-nya, misalnya, 0,5.
		
		\item Kemudian YOLO menghitung IOU dari setiap sel grid yang merupakan area persimpangan dibagi dengan Union Area.
		
		\item Terakhir, ia mengabaikan prediksi sel kisi yang memiliki IOU $\leq$ ambang batas dan mempertimbangkannya dengan IOU > ambang batas.
	\end{itemize}
	
	Pada Gambar \ref{img:IOU} adalah ilustrasi penerapan proses pemilihan grid pada objek kiri bawah. Dapat diamati bahwa objek awalnya memiliki dua kandidat kisi, kemudian hanya "Kisi 2" yang dipilih di bagian akhir.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.9\columnwidth]{bab2/Gambar/Picture35.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{IOU\\(Sumber: Z. Kelta, 2022)}\label{img:IOU}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\item Non-Maximum Supression (NMS)
	
	Menetapkan ambang batas untuk IOU tidak selalu cukup karena sebuah objek dapat memiliki beberapa kotak dengan IOU di luar ambang batas, dan meninggalkan semua kotak tersebut mungkin termasuk kebisingann (\textit{noise}). Di sinilah, dapat menggunakan NMS untuk menyimpan hanya kotak dengan skor probabilitas deteksi tertinggi.
\end{enumerate}

\subsection{Perkembangan YOLO}
\hspace{1,2cm}Sejak rilis pertama YOLO pada tahun 2015, YOLO telah banyak berkembang dengan versi berbeda, seperti pada Gambar \ref{img:Perkembangan-YOLO}. 

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.9\columnwidth]{bab2/Gambar/Picture36.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{Perkembangan YOLO\\(Sumber: Z. Kelta, 2022)}\label{img:Perkembangan-YOLO}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{enumerate}
	\item YOLO atau YOLOv1
	
	Versi pertama YOLO ini adalah pengubah permainan untuk deteksi objek, karena kemampuannya mengenali objek dengan cepat dan efisien.\\
	Namun, seperti banyak solusi lainnya, versi pertama YOLO memiliki keterbatasannya sendiri:
	\begin{itemize}
		\item Kesulitan untuk mendeteksi gambar yang lebih kecil dalam sekelompok gambar, seperti sekelompok orang di stadion. Ini karena setiap kisi dalam arsitektur YOLO dirancang untuk deteksi objek tunggal.
		
		\item Kemudian, YOLO tidak berhasil mendeteksi bentuk baru atau tidak biasa.
		
		\item Terakhir, fungsi kerugian yang digunakan untuk memperkirakan kinerja pendeteksian memperlakukan kesalahan yang sama untuk kotak pembatas kecil dan besar, yang sebenarnya membuat pelokalan yang salah.
	\end{itemize}
	
	\item YOLOv2 atau YOLO9000
	
	YOLOv2 dibuat pada tahun 2016 dengan ide membuat model YOLO lebih baik, lebih cepat, dan lebih kuat.\\
	Peningkatan termasuk tetapi tidak terbatas pada penggunaan Darknet-19 sebagai arsitektur baru, normalisasi batch, resolusi input yang lebih tinggi, lapisan konvolusi dengan anchors, pengelompokan dimensi, dan (5) fitur-fitur halus.
	
	\begin{itemize}
		\item \textit{Batch Normalization}
		
		Menambahkan lapisan normalisasi batch meningkatkan kinerja sebesar 2\% mAP. Normalisasi batch ini menyertakan efek regularisasi, mencegah overfitting.
		
		\item \textit{Higher input resolution}
		
		YOLOv2 secara langsung menggunakan input 448x448 beresolusi lebih tinggi daripada 224x224, yang membuat model menyesuaikan filternya untuk bekerja lebih baik pada gambar beresolusi lebih tinggi. Pendekatan ini meningkatkan akurasi sebesar 4\% mAP, setelah dilatih selama 10 epochs pada data ImageNet.
	\end{itemize}
	
	\item YOLOv3 - Peningkatan Bertahap
	
	Perubahan tersebut terutama mencakup arsitektur jaringan baru: Darknet-53. Ini adalah jaringan saraf 106, dengan jaringan upsampling dan blok residual. Jauh lebih besar, lebih cepat, dan lebih akurat dibandingkan dengan Darknet-19, yang merupakan tulang punggung YOLOv2. Arsitektur baru ini telah bermanfaat di banyak tingkatan:
	
	\begin{itemize}
		\item Prediksi \textit{Bounding Box} Lebih Baik
		
		Model regresi logistic digunakan oleh YOLOv3 untuk memprediksi skor objektivitas untuk setiap kotak pembatas (bounding box).
		
		\item Prediksi Kelas yang Lebih Akurat
		
		Menggantikan penggunaan softmax seperti yang dilakukan di YOLOv2, pengklasifikasi logistik independen telah diperkenalkan untuk memprediksi kelas kotak pembatas secara akurat. Ini bahkan berguna saat menghadapi domain yang lebih kompleks dengan label yang tumpang tindih (Misalnya, $\rightarrow$ Pemain Sepak Bola). Menggunakan softmax akan membatasi setiap kotak hanya memiliki satu kelas, yang tidak selalu benar.
		
	\end{itemize}
	
	\item YOLOv4 - \textit{Optimal Speed dan Accuracy of Object Detection}
	
	Versi YOLO ini memiliki Kecepatan dan Akurasi Deteksi Objek Optimal dibandingkan dengan semua versi sebelumnya dan detektor objek canggih lainnya.\\
	Gambar \ref{img:KomprasiYoloV4-YoloV3} menunjukkan YOLOv4 mengungguli YOLOv3 dan FPS dalam kecepatan masing-masing sebesar 10\% dan 12\%.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.8\columnwidth]{bab2/Gambar/Picture37.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Komparasi YOLOv4 dengan YOLOv3 dan \textit{state-of-the-art} Deteksi Objek Lain \\(Sumber: Z. Kelta, 2022)}\label{img:KomprasiYoloV4-YoloV3}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	YOLOv4 dirancang khusus untuk sistem produksi dan dioptimalkan untuk komputasi paralel.\\
	\textit{Backbone} arsitektur YOLOv4 adalah CSPDarknet53, jaringan yang berisi 29 lapisan konvolusi dengan filter 3 x 3 dan sekitar 27,6 juta parameter.\\
	Arsitektur ini, dibandingkan dengan YOLOv3, menambahkan informasi berikut untuk deteksi objek yang lebih baik:
	
	\begin{itemize}
		\item \textit{Spatial Pyramid Pooling} (SPP) secara signifikan meningkatkan bidang reseptif, memisahkan fitur konteks yang paling relevan, dan tidak memengaruhi kecepatan jaringan.
		
		\item Menggantikan \textit{Feature Pyramid Network} (FPN) yang digunakan di YOLOv3, YOLOv4 menggunakan PANet untuk agregasi parameter dari tingkat deteksi yang berbeda.
		
		\item Augmentasi data menggunakan teknik mosaik yang menggabungkan empat gambar pelatihan selain pendekatan pelatihan permusuhan diri.
		
		\item Menggunakan pemilihan hyper-parameter yang optimal menggunakan algoritma genetika.
		
	\end{itemize}
	
	\item YOLOR - You Only Look One Representation
	
	Sebagai \textit{Unified Network for Multiple Tasks}, YOLOR didasarkan pada jaringan terpadu yang merupakan kombinasi dari pendekatan pengetahuan eksplisit dan implisit.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.8\columnwidth]{bab2/Gambar/Picture38.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Unified Network Architecture\\(Sumber: C. Y. Wang et al, 2021}\label{img:Unified-Network-Architecture}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		Pengetahuan eksplisit adalah pembelajaran normal atau conscious learning. Pembelajaran implisit di sisi lain dilakukan secara tidak sadar (dari pengalaman).\\
		Menggabungkan kedua teknik ini, YOLOR mampu menciptakan arsitektur yang lebih kuat berdasarkan tiga proses: (1) penyelarasan fitur, (2) penyelarasan prediksi untuk deteksi objek, dan (3) representasi kanonis untuk pembelajaran multi-tugas.\\
		Salah satu yang mengalami peningkatan adalah penjajaran prediksi. Pendekatan ini memperkenalkan representasi implisit ke dalam peta fitur dari setiap jaringan piramida fitur (FPN), yang meningkatkan presisi sekitar 0,5\%.\\
		Dari grafik berikut, dapat diamati bahwa YOLOR mencapai kecepatan inferensi data MS COCO yang canggih dibandingkan dengan model lain seperti pada Gambar \ref{img:Performance-YOLOR-YOLOV4}.
		
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.8\columnwidth]{bab2/Gambar/Picture39.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Performance YOLOR vs YOLOv4 dan Model Lainnya\\(Sumber: C. Y. Wang et al, 2021}\label{img:Performance-YOLOR-YOLOV4}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\item YOLOX - Exciding \textit{YOLO Series in 2021}
	
	Ini menggunakan baseline yang merupakan versi modifikasi dari YOLOv3, dengan Darknet-53 sebagai \textit{backbone}.\\
	Diterbitkan dalam makalah \textit{Exceeding} YOLO \textit{Series in 2021}, YOLOX menghadirkan empat karakteristik utama berikut untuk membuat model yang lebih baik dibandingkan dengan versi yang lebih lama.
	
	\begin{itemize}
		\item Kepala terpisah yang efisien: Coupled head yang digunakan pada versi YOLO sebelumnya terbukti mengurangi performa model. YOLOX menggunakan decoupled sebagai gantinya, yang memungkinkan pemisahan tugas klasifikasi dan lokalisasi, sehingga meningkatkan kinerja model.
		
		\item Augmentasi data yang kuat: Integrasi Mosaic dan MixUp ke dalam pendekatan augmentasi data sangat meningkatkan kinerja YOLOX.
		
		\item \textit{Anchor free system}: Algoritma \textit{anchor-based} melakukan pengelompokan di bawah tenda, yang meningkatkan waktu inferensi. Menghapus mekanisme jangkar di YOLOX mengurangi jumlah prediksi per gambar, dan meningkatkan waktu inferensi secara signifikan.
		
		\item SimOTA untuk penetapan label: Pergantian penggunaan pendekatan interseksi penyatuan (IoU), penulis memperkenalkan SimOTA, strategi penetapan label yang lebih kuat yang mencapai hasil canggih dengan tidak hanya mengurangi waktu pelatihan tetapi juga menghindari masalah hiperparameter tambahan. Selain itu, ini meningkatkan peta deteksi sebesar 3\%.
		
	\end{itemize}
	
	\item YOLOv5
	
	YOLOv5, dibandingkan dengan versi lain, tidak memiliki makalah penelitian yang diterbitkan, dan ini adalah versi YOLO pertama yang diimplementasikan di Pytorch, bukan di Darknet.\\
	Dirilis oleh Glenn Jocher pada Juni 2020, YOLOv5, mirip dengan YOLOv4, menggunakan CSPDarknet53 sebagai tulang punggung arsitekturnya. Rilis ini mencakup lima ukuran model yang berbeda: YOLOv5s (terkecil), YOLOv5m, YOLOv5l, dan YOLOv5x (terbesar).\\
	Salah satu peningkatan besar dalam arsitektur YOLOv5 adalah integrasi lapisan Fokus, yang diwakili oleh satu lapisan, yang dibuat dengan mengganti tiga lapisan pertama YOLOv3. Integrasi ini mengurangi jumlah lapisan, dan jumlah parameter dan juga meningkatkan kecepatan maju dan mundur tanpa dampak besar pada peta.\\
	Ilustrasi Gambar \ref{img:Perbandingan-YOLOv4-YOLOv5} membandingkan waktu pelatihan antara YOLOv4 dan YOLOv5.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=0.6\columnwidth]{bab2/Gambar/Picture40.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Perbandingan Waktu Pelatihan antara YOLOv4 dan YOLOv5\\(Sumber: J. Nelson, 2020}\label{img:Perbandingan-YOLOv4-YOLOv5}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\item YOLOv6
	
	Didedikasikan untuk aplikasi industri dengan desain efisien yang ramah perangkat keras dan kinerja tinggi, kerangka kerja YOLOv6 (MT-YOLOv6) dirilis oleh Meituan, sebuah perusahaan e-commerce Tiongkok.\\
	Ditulis dalam Pytorch, versi baru ini bukan bagian dari YOLO resmi tetapi tetap diberi nama YOLOv6 karena tulang punggungnya terinspirasi oleh arsitektur YOLO satu tahap yang asli.\\
	YOLOv6 memperkenalkan tiga peningkatan signifikan pada YOLOv5 sebelumnya: desain tulang punggung dan leher yang ramah perangkat keras, kepala terpisah yang efisien, dan strategi pelatihan yang lebih efektif.\\
	YOLOv6 memberikan hasil yang luar biasa dibandingkan dengan versi YOLO sebelumnya dalam hal akurasi dan kecepatan pada dataset COCO seperti yang diilustrasikan pada Gambar \ref{img:Performance-YOLOv6}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture41.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Comparison of state-of-the-art efficient object detectors. All models are tested with TensorRT 7 except that the quantized model is with TensorRT 8\\(Sumber: C. Li et al, 2022}\label{img:Performance-YOLOv6}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\begin{itemize}
		\item YOLOv6-N mencapai 35,9\% AP pada dataset COCO dengan throughput 1234 (throughput) FPS pada GPU NVIDIA Tesla T4.
		
		\item YOLOv6-S mencapai AP 43,3\% yang canggih pada 869 FPS.
		
		\item YOLOv6-M dan YOLOv6-L juga mencapai kinerja akurasi yang lebih baik masing-masing sebesar 49,5\% dan 52,3\% dengan kecepatan inferensi yang sama.
		
	\end{itemize}
	
	\item YOLOv7
	
	YOLOv7 dirilis pada Juli 2022 di Paper \textit{Trained bag-of-freebies set state-of-the-art real-time object detector}. Versi ini membuat langkah signifikan di bidang deteksi objek, dan melampaui semua model sebelumnya dalam hal akurasi dan kecepatan.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{figure}[H]
		\vspace{-0.1cm}
		%\rule{\columnwidth}{0.1pt}
		\begin{center}
			\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture42.png}
		\end{center}
		\vspace{-0.2cm}
		%\rule{\columnwidth}{0.1pt}
		\captionsetup{justification=centering}
		\caption{Perbandingan YOLOv7 inference time dengan real-time object detector lainnya\\(Sumber: C. Y. Wang et al, 2022}\label{img:Performance-YOLOv7}
	\end{figure}
	%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	YOLOv7 telah membuat perubahan besar dalam (1) arsitekturnya dan (2) pada tingkat bag-of-freebies yang dapat dilatih:
	
	\begin{itemize}
		\item Level Aristektur
		
		YOLOv7 mereformasi arsitekturnya dengan mengintegrasikan Extended Efficient Layer Aggregation Network (E-ELAN) yang memungkinkan model mempelajari fitur yang lebih beragam untuk pembelajaran yang lebih baik.\\
		Selain itu, YOLOv7 menskalakan arsitekturnya dengan menggabungkan arsitektur model asalnya seperti YOLOv4, Scaled YOLOv4, dan YOLO-R. Hal ini memungkinkan model untuk memenuhi kebutuhan kecepatan inferensi yang berbeda.
		
		%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		\begin{figure}[H]
			\vspace{-0.1cm}
			%\rule{\columnwidth}{0.1pt}
			\begin{center}
				\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture43.png}
			\end{center}
			\vspace{-0.2cm}
			%\rule{\columnwidth}{0.1pt}
			\captionsetup{justification=centering}
			\caption{\textit{Compound scaling up depth and width for concatenation-based model}\\(Sumber: C. Y. Wang et al, 2022}\label{img:Compund-Scaling}
		\end{figure}
		%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		
		\item Trainable bag-of-freebies
		
		Istilah bag-of-freebies mengacu pada peningkatan akurasi model tanpa meningkatkan biaya pelatihan, dan inilah alasan mengapa YOLOv7 tidak hanya meningkatkan kecepatan inferensi tetapi juga akurasi deteksi.
		
	\end{itemize}
\end{enumerate}

\section{Object Based Image Analysis (OBIA)}
\hspace{1,2cm}OBIA merupakan teknik klasifikasi yang tidak hanya memandang rona dan tekstur piksel namun berdasarkan dari kesatuan objek, atau dapat dikatakan OBIA adalah pendekatan yang proses klasifikasinya tidak hanya mempertimbangkan aspek spectral naum aspek spasial objek. Data citra penginderaan jauh yang digunakan untuk klasifikasi ini biasanya menggunakan data citra penginderaan jauh resolusi tinggi seperti QUickbird, Ikonos, World View, dll. Klasifikasi ini hamper mirip dengan klasifikasi unsupervised, akan tetapi basis dari klasifikasi OBIA yaitu dengan segmentasi (A. Bakar, 2014).

OBIA mengelompokkan gambar yang mengelompokkan piksel kecil menjadi objek vektor. Alih-alih berbasis per-pixel, segmentasi secara otomatis mendigitalkan gambar untuk pengguna (GIS Geography, 2020).

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture44.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{OBIA Segmentasi Proses Pengelompokkkan Pixel yang hampir sama ke dalam Objek\\(Sumber: GISGeography, 2020)}\label{img:OBIA-Segmentasi-Proses}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Apa yang dilakukan segmentasi adalah meniru apa yang dilakukan mata pengguna. Tetapi dengan objek tersegmentasi ini, pengguna menggunakan properti spektral, geometris, dan spasialnya untuk mengklasifikasikan ke dalam tutupan lahan.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture45.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{OBIA Klasifikasi menggunakan shape, size, dan spectral properties objek untuk klasifikasi setiap objek}\label{img:OBIA-Klasifikasi}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Dua prinsip dasar OBIA adalah klasifikasi dan segmentasi. Segmentasi adalah memecah gambar menjadi objek yang mewakili fitur berbasis darat, sedangkan Klasifikasi adalah mengklasifikasi objek-objek tersebut menggunakan bentuk, ukuran, sifat spasial dan spektralnya. Analis sering menggunakan statistik ini untuk mengklasifikasikan tutupan lahan menggunakan OBIA, yaitu \textit{trees} (pohon) memiliki ketinggian yang bervariasi (standar deviasi \textit{normalized Digital Surface Model} (nDSM)) yang merupakan model elevasi yang menangkap fitur alami dan fitur buatan, seperti gedung, pohon, kabel listrik, dan objek lainnya. Di samping itu, memiliki reflektansi inframerah-dekat yang tinggi (\textit{normalized difference vegetation index} (NDVI) tinggi), sedangkan \textit{grass} memiliki pendek (nDSM rendah), datar (deviasi standar nDSM rendah) dan memiliki reflektansi inframerah-dekat sedang (NDVI sedang). NDVI digunakan untuk mengukur indeks yang menggambarkan tingkat kepadatan, kehijauan suatu tanaman dan kondisi dari suatu vegetasi.

\section{Sentinel-2}
\hspace{1,2cm}Data yang digunakan dalam penelitian ini diambil dari gambar citra satelit Sentinel-2. Sentinel-2 diluncurkan sebagai bagian dari program Copernicus Komisi Eropa pada tanggal 23 Juni 2015 yang dirancang khusus untuk memberikan banyak data dan citra. Satelit dilengkapi dengan sensor multispectral opto-elektronik untuk survei dengan resoulsi Sentinel-2 yaitu 10 hingga 60m di zona spekatral tampak, VNIR, SWIR, termasuk 13 saluran spectral yang memastikan penangkapan perbedaan dalam keadaan vegetasi, termasuk perubahan temporal, dna juga meminimalkan dampkan kualitas fotografi atmosfer. Sentinel-2 memiliki dua satelit dalam misi memungkinkan survei berulang setiap 5 hari di ekuator dan 2-3 hari di garis lintang tengah (EOS, 2020). 

Misi Sentinel-2 terdiri dari dua satelit yang dikembangkan untuk mendukung vegetasi, tutupan lahan, dan pemantauan lingkungan. Satelit Sentinel-2A diluncurkan oleh European Space Agency (ESA) pada 23 Juni 2015, dan beroperasi di orbit sinkron matahari dengan siklus berulang 10 hari. Setelit kedua yaitu Sentinel-2B diluncurkan pada 7 Maret 2017 dan beroperasi dengan akuisisi data yang tersedia di EarthExplorer (USGS EROS, 2020). 

Terdapat Perbandingan antara Sentinel-2 dengan UAV Drone, seperti pada Tabel 2.2.

%%% BENERIN TABEL

\section{Pertanian Presisi}
\hspace{1,2cm}Pertanian presisi atau precision agriculture merupakan suatu sistem pertanian yang mengintegrasikan penggunaan teknologi dalam mengumpulkan informasi, sehingga dapat melakukan proses pertanian secara presisi atau dengan input, tempat, dan waktu yang tepat. Istilah presisi berarti akurat, terakar, dan terukur. Pertanian presisi disebut juga menggunakan input pertanian yang tepat dengan teknik, jumlah, tempat, dan waktu yang tepat untuk menghasilkan produksi panen secara maksimal. Input pertanian meliputi seperti pemupukan, herbisida, insektisida, benih, dan lainnya. Meskipun untuk melakukan pertanian secara akurat ini membutuhkan banyak informasi, cenderung kompleks untuk kebanyakan petani, dan membutuhkan kerjasama dari berbagai multidisiplin ilmu, namun sistem pertanian presisi mampu meingkatkan laba, mengurangi limbah, mengurangi biaya produksi, dan menjaga kualitas lingkungan (J. Taylor et al., 2016). 

Pertanian presisi (PA) merupakan ilmu untuk meningkatkan hasil panen dan membantu keputusan manajemen menggunakan sensor dan alat analisis teknologi tinggi. Pertanian presisi adalah konsep yang digunakan untuk meningkatkan produksi, mengurangi waktu kerja, dan memastikan pengelolaan seperti pupuk, irigasi, dan lainnya berjalan efektif. Perkembangan teknologi, khususnya ketersediaan citra satelit beresolusi tinggi, perkembangan teknologi kendaraan udara tak berawak (UAV), menunjukkan bahwa adopsi sumber data penginderaan jauh dalam pertanian presisi mengalami peningkatan (P. Singh et al., 2020). 

Siklus pertanian presisi terdiri dari tahapan seperti Gambar 2.46.
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Picture46.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{Siklus Pertanian Presisi\\(Sumber: A. Comparetti, 2011)}\label{img:Siklus-Pertanian-Presisi}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
	\item Pengukuran parameter tanah dan tanaman dengan bantuan pemetaan spasial dan pemantauan kondisi cuaca setempat (pengumpulan data);
	
	\item pemetaan parameter tanah dan tanaman dalam lapangan (pengumpulan data);
	
	\item pemetaan dan integrasi data dengan bantuan aplikasi (interpretasi);
	
	\item pemantauan kesuburan dan penaburan (aplikasi);
	
\end{itemize}
Dalam menerapkan pertanian presisi diperlukan instrumen berikut (A. Comparetti, 2011):

\begin{itemize}
	\item Sistem penentuan posisi satelit, untuk penginderaan posisi di mana setiap parameter lapangan yang diukur harus direferensikan secara geografis dan, kemudian, juga posisi di mana input (seperti, tanaman, lahan) yang terdeteksi oleh  mesin dapat diterapkan kebutuhannya di setiap area lahan (zona pengelolaan).
	
	\item Sensor, untuk mengukur parameter tanah dan tanaman di lapangan.
	
	\item Perangkat (devices), untuk menyiapkan dan mengontrol aplikasi input tanaman tingkat variabel spasial.
	
	\item Perangkat lunak, untuk membuat peta parameter tanah dan tanaman dalam lahan dan aplikasi input tanaman dengan data dari citra penginderaan, dan juga untuk menginterpretasikan data terukur;
	
\end{itemize}

\section{Kelapa Sawit}
\hspace{1,2cm}Kelapa sawit adalah tanaman sejenis palma berakar serabut atau monokotil. Bagian tanaman yang bernilai ekonomis adalah buah. Masing-masing dari seribu atau lebih buah dalam tandan buah segar itu terdiri dari inti sawit (kernel) yang dikelilingi) oleh daging buah (mesocarp). Di pabrik kelapa sawit, sangat sedikit buah yang terbuang sia-sia karena pabrik tersebut mengubah setiap buah kelapa sawit menjadi minyak kelapa sawit dan minyak inti sawit), bahkan limbah dari setiap buah sawitpun di daur ulang di perkebunan sebagai pupuk atau diolah sebagai bahan bakar biomass. Sangat sedikit sekali buah kelapa sawit terbuang karena baik inti kelapa sawit dan dagingnya sama-sama digunakan untuk menghasilkan minyak.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.3\columnwidth]{bab2/Gambar/Picture47.jpg}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\captionsetup{justification=centering}
	\caption{Buah Kelapa Sawit(Inti dan Daging Sawit)}\label{img:Buah-Kelapa-Sawit}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Satu tandan tanaman dewasa beratnya mencapai 20 - 35 kg, bahkan ada yang mencapai di atas 40 kg, tergantung pada perawatan. Tandan tersusun dari 200 - 600 buah masing-masing sekitar 20-35 gram. Buah diambil minyaknya dengan hasil sabut (daging buah/mesocarp) menghasilkan minyak kasar (CPO) 20-26\%, inti sawit sebanyak 6\% yang menghasilkan minyak inti (PKO) 3-4\%. Kadar \% dihitung dari berat tandan buah segar (Smart Agribusiness and Food, 2017).

\begin{enumerate}[label=(\alph*)]
	\item Usia Tanam
	
	Umur atau usia ekonomis tanaman kelapa sawit yang dibudidayakan bisa mencapai usia hingga 25 tahun. Pada usia tanam sudah tinggi, sehingga sulit dipanen, tandanya sudah jarang sehingga secara perhitungan tidak ekonomis lagi. Pengelompokkan berdasarkan masa berbuah (PTPN, 2018), seperti Tabel \ref{tbl:Pengelompokkan-Berdasarkan-Masa-Berubah} berikut ini:
	
	%%%%%%%%%%%%%%%%%%%%%%%TABEL SEDERHANA%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{singlespace}
		\begin{table}[H]
			\centering
			\caption{Pengelompokkan Berdasarkan Masa Berbuah}
			\label{tbl:Pengelompokkan-Berdasarkan-Masa-Berubah}
			\begin{tabular}{|p{6cm}|p{6cm}|}
				\hline
				\multicolumn{1}{|c|}{Kelompok}   & Masa Berbuah (Tahun) \\ \hline
				Tanaman Belum Menghasilkan (TBM) & 0-3                  \\ \hline
				Tanaman Menghasilkan             & \textgreater{}3      \\ \hline
			\end{tabular}
		\end{table}
	\end{singlespace}
	%%%%%%%%%%%%%%%%%%%%%%%TABEL SEDERHANA%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\item Produktivitas Tanaman Kelapa Sawit Menurut Umur Tanaman
	
	Produktivitas tanaman kelapa sawit (tandan buah segar (TBS)) menurut umur tanaman dalam Kondisi Kebun Percobaan Balit Marihat berdasarkan PTPN. VII tahun 1993 dalam \textit{lecture note} "Budi Daya Kelapa Sawit" (S. Yahya \& Suwarto, 2021), seperti Tabel 2.4. berikut ini:
	
	%%%%%%%%%%%%%%%%%%%%%%%TABEL SEDERHANA%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{singlespace}
		\begin{table}[H]
			\centering
			\caption{Produktivitas Tanaman Kelapa Sawit Menurut Umur Tanaman dalam Kondisi Kebun Percobaan Balit Marihat}
			\label{tbl:Produktivitas-Tanaman-Kelapa-Sawit}
			\begin{tabular}{|c|c|}
			\hline
			
			Umur Di Lapangan (Tahun) & \begin{tabular}[c]{@{}c@{}}Produksi    Produksi TBS\\ (ton/ha/Thn)\end{tabular} \\ \hline
			
			4 & 8 \\ \hline
			
			5 & 15 \\ \hline
			
			6 & 17 \\ \hline
			
			7 & 18 \\ \hline
			
			8 & 20 \\ \hline
			
			9 & 21 \\ \hline
			
			10 & 23 \\ \hline
			
			11 & 25 \\ \hline
			
			12 & 26 \\ \hline
			
			13 & 30 \\ \hline
			
			14 & 30 \\ \hline
			
			15 & 30 \\ \hline
			
			16 & 30 \\ \hline
			
			17 & 29 \\ \hline
			
			18 & 28 \\ \hline
			
			19 & 28 \\ \hline
			
			20 & 25 \\ \hline
			
			21 & 23 \\ \hline
			
			22 & 20 \\ \hline
			
			23 & 18 \\ \hline
			
			24 & 18 \\ \hline
			
			25 & 18 \\ \hline
				
				
			\end{tabular}
		\end{table}
	\end{singlespace}
	%%%%%%%%%%%%%%%%%%%%%%%TABEL SEDERHANA%%%%%%%%%%%%%%%%%%%%%%%%%
\end{enumerate}








	
\section{Teknologi Informasi}
\hspace{1,2cm}Informasi adalah proses transmisi dan transfer pengetahuan: bentuk, data, dan konsep, studi dengan tujuan membuatnya dapat diakses oleh orang lain, lembaga atau masyarakat. Kualitas proses ini akan menentukan diterima atau tidaknya perubahan perilaku dan sikap individu tersebut. Teknologi informasi berupa perangkat apapun yang memiliki kapasitas untuk mengolah data dan atau informasi, baik secara sistematis maupun dinamis. Teknologi informasi juga dapat diterapkan pada produk maupun dalam suatu proses \citep{Victoria2020}.

Telekomunikasi adalah sistem komunikasi jarak jauh dengan teknologi, terutama melalui sinyal listrik atau gelombang elektromagnetik. sistem komunikasi juga merupakan bagian dari perangkat keras (seperti TV, ponsel) atau algoritma yang membaca informasi data masukan, memprosesnya dan mengirimkan data keluaran melalui saluran tertentu. gambar \ref{dasar telekomunikasi} merupakan gambaran umum dasar telekomunikasi.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.9\columnwidth]{bab2/Gambar/SANDY. dasar telkom.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{dasar telekomunikasi \citep{ElSaba2018}}\label{dasar telekomunikasi}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textit{Digital Television} (DTV) merupakan transmisi sinyal audiovisual televisi menggunakan pengkodean digital, berbeda dengan teknologi televisi analog sebelumnya yang menggunakan sinyal analog. Perkembangan ini dianggap sebagai kemajuan inovatif dan merupakan evolusi signifikan pertama dalam teknologi televisi sejak televisi berwarna pada 1950-an. DTV dapat berupa \textit{High Definition Television} (HDTV) atau transmisi simultan dari berbagai program \textit{Standar Definition Television} (SDTV), yang merupakan kualitas gambar yang lebih rendah daripada HDTV tetapi jauh lebih baik daripada televisi analog \citep{Kruger2002}.

\section{Teknik Televisi Digital}
\hspace{1,2cm}Layanan DTV mempunyai tiga komponen utama yang harus ada agar konsumen dapat menikmati pengalaman menonton televisi "definisi tinggi" yang sepenuhnya terwujud.

\begin{enumerate}
	\item pemrograman digital harus tersedia. Pemrograman digital adalah konten yang diproduksi dengan kamera digital dan peralatan produksi digital lainnya. Peralatan tersebut berbeda dari apa yang saat ini digunakan untuk menghasilkan pemrograman analog konvensional.
	\item pemrograman digital harus dikirimkan kepada konsumen melalui sinyal digital. Sinyal digital dapat disiarkan melalui gelombang udara (membutuhkan menara transmisi baru atau antena DTV di menara yang ada). Sinyal digital ditransmisikan oleh teknologi televisi kabel atau satelit, atau disampaikan oleh sumber yang direkam sebelumnya seperti \textit{disk video digital} (DVD)
	\item konsumen harus memiliki produk televisi digital yang mampu menerima sinyal siaran digital, konsumen dapat membeli monitor digital disertai dengan \textit{set-top converter box}. televisi digital juga dapat terintegrasi dengan kemampuan pengaturan digital yang sudah dibuat oleh produsen \citep{Kruger2002}
\end{enumerate}

Standar penyiaran televisi digital yang berbeda telah diadopsi di berbagai belahan dunia diantaranya \textit{Digital Video Broadcasting} (DVB) menggunakan modulasi \textit{Orthogonal frequency-division multiplexing} (OFDM) dan mendukung transmisi hierarkis. Standar ini telah diadopsi di Eropa, Afrika, Asia, dan Australia, dengan total sekitar 60 negara. \textit{Advanced Television Systems Committee} (ATSC) menggunakan modulisi \textit{8-level vestigial sideband modulation} (8VSB) untuk penyiaran terestrial. Standar ini telah diadopsi oleh 6 negara: Amerika Serikat, Kanada, Meksiko, Korea Selatan, Republik Dominika dan Honduras \citep{dtvstatus2017}.  \textit{Integrated Services Digital Broadcasting} (ISDB) adalah sistem yang dirancang untuk menyediakan penerimaan yang baik untuk penerima tetap dan juga penerima portabel atau seluler. ISDB mendukung transmisi hierarkis hingga tiga lapisan dan menggunakan video MPEG-2 dan \textit{Advanced Audio Coding}. Standar ini telah diadopsi di Jepang dan Filipina. ISDB-T International adalah adaptasi dari standar ini menggunakan H.264 / MPEG-4 AVC, yang telah diadopsi di sebagian besar negara-negara Amerika Selatan dan Afrika berbahasa Portugis \citep{Ong2010}.


\textit{Digital Terrestrial Multimedia Broadcasting} (DTMB) mengadopsi teknologi OFDM \textit{Time-Domain Synchronous} (TDS) dengan kerangka sinyal pseudo-acak untuk berfungsi sebagai \textit{Gate Interval} (GI) dari blok OFDM dan simbol pelatihan. Standar DTMB telah diadopsi di Republik Rakyat Tiongkok, termasuk Hong Kong dan Makau \citep{Ong2010}. \textit{Digital Multimedia Broadcasting} (DMB) adalah teknologi transmisi radio digital yang dikembangkan di Korea Selatan sebagai bagian dari proyek TI nasional untuk mengirim multimedia seperti TV, radio dan datacasting ke perangkat seluler seperti ponsel, laptop dan sistem navigasi GPS \citep{Baek_2008}. Gambar \ref{Sistem penyiaran digital untuk televisi terestrial} dan tabel \ref{Status DTV membandingkan sistem penyiaran digital di seluruh dunia ATSC, DTMB, DVB-T/DVB-T2, dan ISDB-T} merupakan penyebaran sistem DVB pada seluruh dunia \citep{dtvstatus2017}.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/Sistem penyiaran digital untuk televisi terestrial.jpg}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Sistem penyiaran digital untuk televisi terestrial \citep{dtvstatus2017}}\label{Sistem penyiaran digital untuk televisi terestrial}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%TABEL SEDERHANA%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{singlespace}
	\begin{table}[H]
		\centering
		\caption{Status DTV membandingkan sistem penyiaran digital di seluruh dunia ATSC, DTMB, DVB-T/DVB-T2, dan ISDB-T \citep{dtvstatus2017}}
		\label{Status DTV membandingkan sistem penyiaran digital di seluruh dunia ATSC, DTMB, DVB-T/DVB-T2, dan ISDB-T}
		\begin{tabular}{|p{3cm}|p{10cm}|}
			\hline
			\rowcolor[HTML]{E7E7E7} 
			\textbf{System} & \textbf{Explanation} \\ \hline
			\rowcolor[HTML]{062A5E} 
			{\color[HTML]{FFFFFF} DVB-T/DVB-T2} & {\color[HTML]{FFFFFF} Broadcasting via DVB-T/DVB-T2 is actively in use.} \\ \hline
			\rowcolor[HTML]{0067B1} 
			{\color[HTML]{DDDDDD} DVB-T/DVB-T2 adopted} & {\color[HTML]{DDDDDD} Countries which have adopted the DVB-T/DVB-T2 system.} \\ \hline
			\rowcolor[HTML]{79BDE8} 
			DVB-T/DVB-T2 trial broadcasts & Those countries undertake trials with DVB-T/DVB-T2. \\ \hline
			\rowcolor[HTML]{C1E3EF} 
			RRC06 & The according countries participate in the Regional Radiocommunications Conference 2006 of the ITU (International Telecommunication Union). It can be assumed that all countries taking part will ultimately use the DVB-T/DVB-T2 system when they move from analog to digital. \\ \hline
			\rowcolor[HTML]{0A6927} 
			{\color[HTML]{FFFFFF} ATSC} & {\color[HTML]{FFFFFF} Broadcasting via the ATSC system is actively in use.} \\ \hline
			\rowcolor[HTML]{62B56C} 
			ATSC adopted & Countries which have adopted the ATSC system. \\ \hline
			\rowcolor[HTML]{BBE5B7} 
			ATSC trial broadcasts & Those countries undertake trials with ATSC. \\ \hline
			\rowcolor[HTML]{BE4674} 
			{\color[HTML]{FFFFFF} ISDB-T} & {\color[HTML]{FFFFFF} Broadcasting via ISDB-T is actively in use.} \\ \hline
			\rowcolor[HTML]{F497C3} 
			ISDB-T adopted & Countries which have adopted the ISDB-T system. \\ \hline
			\rowcolor[HTML]{F4BCD6} 
			ISDB-T trial broadcasts & Those countries undertake trials with ISDB-T. \\ \hline
			\rowcolor[HTML]{F184F8} 
			{\color[HTML]{FFFFFF} SBTVD-T} & {\color[HTML]{FFFFFF} Broadcasting via SBTVD-T is actively in use.} \\ \hline
			\rowcolor[HTML]{F4AFF8} 
			SBTVD-T adopted & Countries which have adopted the SBTVD-T system. \\ \hline
			\rowcolor[HTML]{FD9D1F} 
			{\color[HTML]{FFFFFF} DTMB} & {\color[HTML]{FFFFFF} Broadcasting via DTMB is actively in use.} \\ \hline
			\rowcolor[HTML]{FDC070} 
			DTMB adopted & Countries which have adopted the DTMB system. \\ \hline
			\rowcolor[HTML]{FDDFB8} 
			DTMB trial broadcasts & Those countries undertake trials with DTMB. \\ \hline
			\rowcolor[HTML]{DEDEDE} 
			Commercial DVB-T services & No formal adoption of a DTT standard or undecided countries \\ \hline
		\end{tabular}
	\end{table}
\end{singlespace}
%%%%%%%%%%%%%%%%%%%%%%%TABEL SEDERHANA%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Digital Video Broadcasting Terestial 2 (DVB-T2)}
\hspace{1,2cm}Proyek\textit{ Digital Video Broadcasting} (DVB), merupakan suatu badan yang bertanggung jawab untuk membuat spesifikasi DVB dan secara resmi diresmikan pada bulan September 1993. Proyek ini didahului oleh Kelompok Peluncuran Eropa untuk Penyiaran Video Digital. Proyek ini terdiri dari kelompok sukarela yang terdiri dari lebih dari 210 organisasi yang telah bergabung untuk memungkinkan pengembangan standar untuk DVB di semua bagian dunia, serta pengenalan awal layanan DVB \citep{Reimers_1998}. Sistem DVB mendistribusikan data menggunakan berbagai pendekatan yaitu:
\begin{enumerate}
	\item Transmisi Satellite (S):
		\begin{enumerate}[label=(\alph*)]
			\item DVB-S
			\item DVB-S2
		\end{enumerate}
	\item Transmisi Kabel (C):
		\begin{enumerate}[label=(\alph*)]
			\item DVB-C
			\item DVB-C2
		\end{enumerate} 
	\item Transmisi televisi terestrial (T): 
		\begin{enumerate}[label=(\alph*)]
			\item DVB-T
			\item DVB-T2 untuk televisi terestrial digital  
		\end{enumerate}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%TABEL SEDERHANA%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{singlespace}
	\begin{table}[H]
		\centering
		\caption{Fitur DVB-S2, DVB-C2 dan DVB-T2 (SANDY 4.)}
		\label{Fitur DVB-S2, DVB-C2 dan DVB-T2}
\begin{tabular}{|p{2cm}|p{3cm}|p{3cm}|p{3cm}|}
	\hline
	Category & DVB-T2 & DVB-C2 & DVB-S2 \\ \hline
	Input Interface & Multiple Transport Stream and Generic Stream   Encapsulation (GSE) & Multiple Transport Stream and Generic Stream   Encapsulation (GSE) & Multiple Transport Stream and Generic Stream   Encapsulation (GSE) \\ \hline
	Code rate & 1/2, 3/5, 2/3, 3/4, 4/5, 5/6 & 1/2, 2/3, 3/4, 4/5, 5/6, 8/9, 9/10 & 1/4, 1/3, 2/5, 1/2, 3/5, 2/3, 3/4, 4/5, 5/6, 8/9, 9/10 \\ \hline
	Interleaving & Bit, Cell, Time, Frequency & Bit, Time, Frequency & Bit \\ \hline
	Modulation Scheme & QPSK, 16QAM, 64QAM, 256QAM & 16QAM to 4096QAM & QPSK to 8-PSK, 16-APSK, 32-APSK \\ \hline
	Modulation & OFDM & OFDM & Singe carrier \\ \hline
	Guard Interval & 1/4, 19/256, 1/8, 9/128, 1/16, 1/32, 1/128 & 1/64, 1/128 & - \\ \hline
	FFT Size & 1K, 2K, 4K, 8K, 16K, 32K & 4K & - \\ \hline
	Pilots & Scaterred, edge, continual, P2, frame-closing & Scaterred, edge, continual, P2, preamble & 36 pilot symbols \\ \hline
\end{tabular}
	\end{table}
\end{singlespace}
%%%%%%%%%%%%%%%%%%%%%%%TABEL SEDERHANA%%%%%%%%%%%%%%%%%%%%%%%%%

Tabel \ref{Fitur DVB-S2, DVB-C2 dan DVB-T2} merupakan fitur yang ada pada DVB-S2, DVB-C2 dan DVB-T2. DVB-T2 dipilih pada penelitian ini karena merupakan salah satu standar teknis terbaru yang dikembangkan oleh Proyek DVB untuk DTT (\textit{Digital Terrestrial Television}). DVB-T2 juga dikenal sebagai siaran digital melalui sistem terestrial sejak tahun 2006 dan merupakan perpanjangan dari sistem DVB-T sebagai program generasi kedua untuk meningkatkan efisiensi sistem total \citep{Yaacob2019}. DVB-T2 adalah standardisasi generasi kedua dari DVB-T. DVB-T2 menyediakan enam ukuran  \textit{fast Fourier transform} (FFT) hingga 32K FFT, tujuh  \textit{guard interval} (GI) yang beragam, dan empat skema modulasi berbasis modulasi OFDM hingga 256-\textit{Quadrature Amplitude Modulation} (QAM). DVB-T2 disasarkan pada kode LDPC (Low-Density Parity-Check) dan BCH (Bose-Chaudhuri-Hocquenghem) yang digabungkan dengan berbagai tingkat kode \citep{Lee2019}. 

Tabel \ref{tabel1} menunjukkan parameter transmisi yang dapat digunakan pada DVB-T dan DVB-T2. Perbedaan diantaranya ditandai dengan huruf cetak tebal. Parameter yang membedakan salah satunya \textit{Input Interface} pada DVB-T2 sudah mendukung GSE. GSE adalah protokol lapisan tautan data (\textit{data link layer}) yang ditentukan oleh DVB. GSE menyediakan sarana untuk membawa protokol berorientasi paket seperti IP di atas lapisan fisik (\textit{physical layer}) uni-directional dan memiliki dukungan untuk enkapsulasi multi-protokol (IPv4, IPv6, MPEG, ATM, Ethernet, VLAN 802.1pQ). \textit{Bitrate} yang digunakan pada DVB-T2 lebih besar dari DVB-T yaitu hingga 32kbit/s per simbol menjadi sistem yang cocok untuk membawa sinyal HDTV pada saluran TV terestrial \citep{DVBProject2013}. Alur proses transmitter DVB-T2 ditunjukkan pada gambar \ref{Sistem pemancar DVB-T2}.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.9\columnwidth]{bab2/Gambar/Sistem pemancar DVB-T2.jpg}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Sistem pemancar DVB-T2 \citep{Hou2010}}\label{Sistem pemancar DVB-T2}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%TABEL SEDERHANA%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{singlespace}
\begin{table}[H]
	\centering
	\caption{Spesifikasi DVB-T dan DVB-T2 \citep{Yaacob2019}}
	\label{tabel1}
\begin{tabular}{|p{2cm}|p{5cm}|p{5cm}|}
	\hline
	Category & DVB-T & DVB-T2 \\ \hline
	Input Interface & Single Transport Stream (TS) & Multiple Transport Stream and \textbf{Generic Stream   Encapsulation (GSE)} \\ \hline
	FEC Rate & Convolutional Coding + Reed-Solomon, 1/2, 2/3, 3/4, 7/8 & \textbf{LDPC + BCH}, 1/2, \textbf{3/5}, 2/3, \textbf{4/5, 5/6} \\ \hline
	Modulation Scheme & QPSK, 16QAM, 64QAM & QPSK, 16QAM, 64QAM, \textbf{256QAM} \\ \hline
	Guard Interval & 1/4, 1/8, 1/16, 1/32 & 1/4, \textbf{19/256}, 1/8, \textbf{9/128}, 1/16, 1/32, \textbf{1/128} \\ \hline
	IFFT Point & 2048, 8192 & 2048, 4096, 8192, \textbf{16384, 32768} \\ \hline
	\end{tabular}
\end{table}
\end{singlespace}
%%%%%%%%%%%%%%%%%%%%%%%TABEL SEDERHANA%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%TABEL LONGTABLE%%%%%%%%%%%%%%%%%%%
%	\begin{singlespace}
%\begin{longtable}{|p{3cm}|p{3cm}|p{3cm}|p{3cm}|}
%	\caption{Perbandingan teknik substitusi dan transposisi \citep{Devi2019}}
%	\label{tabel2} \\
%	\hline
%	\textbf{Techniques} & \textbf{Caesar Cipher} & \textbf{Play Fair Cipher} & \textbf{Hill Cipher} \\ \hline
%	\textbf{Key Type} & \textit{Subtitution} & \textit{Subtitution} & \textit{Subtitution} \\ \hline
%	\textbf{Block Size} & 1 & 2 & m \\ \hline
%	\textbf{Key Size} & \textit{Fixed number} & \textit{Fixed} (25!) & \textit{Variable} \\ \hline
%	\textbf{Attack Type} & \textit{Brute force attack} & \textit{Cipher text only} & \textit{Known plaintext attack} \\ \hline
%	\textbf{Algorithm Strength} & \textit{Only 25 keys possible} & 26*26=676 \textit{diagrams possible} & \textit{Hide single letter frequency distribution} \\ \hline
%	\textbf{Encryption and Decryption Process} & \textit{Symmetric} & \textit{Symmetric} & \textit{Symmetric} \\ \hline
%	\textbf{Key Factor (uniqueness) about the technique} & \textit{Simple substitution with alphabet} & \textit{Use pair of letters and substitute with} 5x5\textit{ matrix designed with key and remaining alphabets} & \textit{Based on linear algebra, convert plaintext into matrix based on ASCII value} \\ \hline
%	\hline
%	\textbf{Techniques} & {\textbf{Polyalphabetic Cipher}} & {\textbf{Rail Fence}} & {\textbf{Columnar Transpotition}} \\ \hline
%	\textbf{Key Type} & \textit{Subtitution} & \textit{Permutation} & \textit{Permutation} \\ \hline
%	\textbf{Block Size} & \textit{Variable length} & \textit{Variable length (depth)} & \textit{Equal to key size} \\ \hline
%	\textbf{Key Size} & \textit{Equal to message length} & \textit{Depth size is variable} & \textit{Variable} \\ \hline
%	\textbf{Attack Type} & \textit{Cipher text and plaintext known attack} & \textit{Brute force attack} & \textit{Frequency analysis attack} \\ \hline
%	\textbf{Algorithm Strength} & \textit{Multiple cipher text letters for each plaintext letter} & \textit{Depth size} & \textit{Multiple encryption are possible to a single message} \\ \hline
%	\textbf{Encryption and Decryption Process} & \textit{Symmetric} & \textit{Symmetric} & \textit{Symmetric} \\ \hline
%	\textbf{Key Factor (uniqueness) about the technique} & \textit{Plaintext is written downwards on successive rails of an imaginary fence, then moving up when we get to the bottom} & \textit{Plaintext is written downwards on successive rails of an imaginary fence, then moving up when we get to the bottom} & \textit{Plaintext is written out in rows of a fixed length} \\ \hline
%\end{longtable}
%\end{singlespace}
%%%%%%%%%%%%%%%%%%%%TABEL LONGTABLE%%%%%%%%%%%%%%%%%%%

%\begin{equation}
%	\begin{aligned}
%		PSNR = 10 log_{10}(\frac{C_{max}^{2}}{MSE})
%	\end{aligned}
%\end{equation}
%
%Semakin rendah MSE, semakin rendah kesalahan yang dihasilkan. Di mana MSE dinyatakan sebagai:
%
%\begin{equation}
%	\begin{aligned}
%		MSE = \frac{1}{2}\sum _{x=1}^{M}\sum _{y=1}^{N}(S_{xy}-C_{xy})^{2}
%	\end{aligned}
%\end{equation}
%Dimana:
%\newline
%$C_{max}$ 		\hspace{1.1cm}: nilai piksel terbesar pada gambar sampul, \newline
%$x$ dan $y$ 	\hspace{0.6cm}: koordinat piksel pada gambar, \newline
%$M$ dan $N$ 	\hspace{0.25cm}: dimensi gambar, \newline
%$S$ 			\hspace{1.7cm}: gambar stego, \newline
%$C$				\hspace{1.65cm}: gambar sampul. \newline

%Berikut ini adalah contoh perhitungan dari PSNR dan MSE:
%\[
%a = 
%\begin{bmatrix} 
%	7 & 1 \\ 
%	2 & 3
%\end{bmatrix}
%;
%b = 
%\begin{bmatrix} 
%	2 & 1 \\ 
%	1 & 1
%\end{bmatrix}
%\]
%
%\[
%MSE = \frac{(7-2)^{2}+(1-1)^{2}+(2-1)^{2}+(3-1)^{2}}{2 * 2}
%\]
%
%\[
%MSE = \frac{25+0+1+4}{4} = \frac{30}{4} = 7,5
%\]
%
%\[
%PSNR = 10_{log 10}(\frac{7^{2}}{7,5}) = 8,151
%\]

\section{Jenis Kompresi Transmisi Video Digital}
\hspace{1,2cm}Kompresi transmisi video digital adalah proses mengurangi ukuran data video sebelum dikirimkan melalui jaringan. Ini dilakukan untuk memastikan bahwa video dapat diterima dengan cepat dan dengan kualitas yang baik, meskipun dengan kapasitas bandwith yang terbatas. Kompresi video menggunakan algoritma kompresi untuk menghapus informasi redundan dalam video dan mengurangi ukuran data. Setelah video diterima, algoritma dekompresi digunakan untuk memulihkan video ke bentuk aslinya. Ada berbagai jenis kompresi video digital yang digunakan, seperti MPEG-2, MPEG-4 AVC/H.264, VC-1, VP9, dan HEVC. \citep{Salomon2010}.

\subsection{Video H.222 MPEG-TS}
\hspace{1,2cm}\textit{Moving Pictures Experts Group Transport Stream} (MPEG-TS) dipilih untuk pengkodean sumber audio dan video untuk pembuatan aliran dasar program. \textit{Transport Stream} MPEG-2, juga disebut MPEG-2 atau MPEG-2 TS atau hanya TS, adalah format khusus untuk mentransmisikan video MPEG (MPEG-1, MPEG-2, atau MPEG-4) dalam sebuah kontainer. TS menetapkan format wadah yang mengenkapsulasi aliran elemental paket (PES), dengan fitur koreksi kesalahan dan pola sinkronisasi untuk menjaga integritas transmisi ketika saluran komunikasi yang membawa aliran mengalami degradasi \citep{ISO/IEC2022}.

MPEG-TS (MPEG Transport Stream) adalah standar transmisi untuk mengirimkan video digital dan audio dalam siaran televisi digital. Dalam siaran televisi digital, data video dan audio dikompresi menggunakan standar kompresi seperti MPEG-2 atau H.264, kemudian diteruskan dalam bentuk paket-paket yang disebut Transport Stream (TS). TS ini mengandung informasi tentang data video dan audio, serta informasi tambahan seperti pengaturan siaran dan informasi program. TS ini kemudian diteruskan melalui jaringan transmisi seperti saluran satelit atau jaringan kabel. Setelah sampai pada penerima, TS didekode dan diterjemahkan menjadi video dan audio yang dapat dilihat dan didengar  \citep{Hoelzer2005,ISO/IEC2022}.

MPEG-TS menggunakan tiga jenis frame (I, P, dan B) untuk mewakili video. Pengaturan GOP menentukan pola tiga jenis frame yang akan digunakan. Ketiga tipe gambar ini antara lain Intra (\textit{I-frame}), juga dikenal sebagai \textit{frame} kunci. Setiap GOP berisi satu \textit{I-frame}. \textit{I-frame} adalah satu-satunya jenis \textit{frame} MPEG-TS yang dapat didekompresi sepenuhnya tanpa referensi ke \textit{frame} yang mendahului atau mengikutinya. Ini juga merupakan data yang paling berat, membutuhkan ruang disk paling banyak.

Berikutnya\textit{ Predicted frame (P-frame)}, dienkodekan dari gambar diprediksi berdasarkan pada \textit{frame} I- atau P yang terdekat dan sebelumnya. \textit{P-frame} biasanya membutuhkan ruang disk jauh lebih sedikit daripada \textit{I-frame} karena mereka merujuk pada I- atau P-\textit{frame} sebelumnya dalam GOP. Terakhir ada \textit{Bi-directional (B-frame)}, dikodekan dari interpolasi \textit{frame} referensi yang berhasil dan sebelumnya, baik dari \textit{I-frame} atau \textit{P-frame}. \textit{B-frame} adalah jenis frame yang paling efisien penyimpanan, membutuhkan ruang disk paling sedikit. Penggunaan B dan \textit{P-frame} memungkinkan MPEG-TS untuk menghapus redudansi temporal, berkontribusi pada kemampuannya untuk mengompres video secara efisien \citep{Inc.2012}.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.9\columnwidth]{bab2/Gambar/H.264 AVC Struktur GOP.jpg}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{H.264/AVC Struktur GOP \citep{Inc.2012}}\label{H.264/AVC Struktur GOP}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Video H.264 MPEG-4}
\hspace{1,2cm}MPEG-4 adalah metode mendefinisikan kompresi data digital audio dan visual (AV). Ini diperkenalkan pada akhir 1998 dan menetapkan standar untuk sekelompok format pengkodean audio dan video dan teknologi terkait yang disetujui oleh Kelompok Ahli Gambar Bergerak ISO / IEC (MPEG) (ISO / IEC JTC1 / SC29 / WG11) di bawah standar formal ISO / IEC 14496-Pengkodean objek audio-visual. Penggunaan MPEG-4 termasuk kompresi data AV untuk web (\textit{streaming media}) dan distribusi CD, suara (telepon, \textit{videophone}) dan aplikasi siaran televisi. Standar MPEG-4 dikembangkan oleh kelompok yang dipimpin oleh Touradj Ebrahimi (kemudian presiden JPEG) dan Fernando Pereira \citep{Ebrahimi2002}.

Dibandingkan dengan MPEG-2, AVC MPEG-4 yang jauh lebih baik (H.264) video codec memungkinkan kecepatan data diturunkan 30 hingga 50\%. Ini berarti bahwa sinyal SDTV sekarang dapat dikompresi hingga kira- kira. 1,5 - 3 Mbit/s dibandingkan dengan laju data 2-7 Mbit/s, laju data asli yang tidak terkompresi adalah 270 Mbit/s. Menggunakan MPEG-4, sinyal HDTV dapat menyusut menjadi sekitar 10 Mbit / dtk dari aslinya 1,5 Gbit/ dtk. MPEG-2 membutuhkan sekitar 20 Mbit/s untuk ini \citep{Fischer2010}.


\section{\textit{Signal to Noise Ratio} (SNR)}
\hspace{1,2cm}SNR didefinisikan dengan baik dan dipahami dalam teknik listrik dan komunikasi. SNR sering digunakan dalam pekerjaan yang berkaitan dengan proses pengukuran dan desain instrumen, tetapi relatif sedikit digunakan dalam berorientasi aplikasi(SANDY 5). SNR dalam bentuknya yang paling sederhana didefinisikan sebagai rasio kekuatan sinyal terhadap kekuatan \textit{noise}. Dalam praktiknya, \textit{noise} dikenali pada echogram sebagai latar belakang umum acak. \textit{Noise} tersebut dapat dihilangkan dengan memilih \textit{threshold} yang akan memberikan sinyal bebas interferensi tetapi tidak secara signifikan mengurangi sinyal yang diinginkan dalam rentang kedalaman sinyal yang diinginkan \citep{Welvaert2013}. Nilai SNR yang lebih tinggi menunjukkan kualitas sinyal yang lebih baik dan SNR yang rendah menunjukkan ada banyaknya \textit{noise} pada sinyal tersebut \citep{Altunian2021}.

SNR biasanya dinyatakan dalam Desibel (dB), terutama dalam aplikasi audio dan suara karena rentang dinamis pendengaran manusia yang sangat besar \citep{Kessel2018}. Desibel (dB) sering digunakan untuk menyatakan rasio tidak berunit. dB bukanlah "satuan" dalam arti meter, newton, detik. Desibel dapat dianggap seperti persen, lusin atau bagian per juta sehingga dB adalah bilangan tak berdimensi \citep{Centauri2013}. Desibel menjadi cara untuk mengekspresikan nilai pada skala logaritmik. Komponen audio, sebagai contoh mempunyai SNR senilai 100 dB, itu berarti level sinyal audio 100 dB lebih tinggi daripada \textit{noise}. Spesifikasi SNR 100 dB jauh lebih baik daripada yang 70 dB atau kurang.

Sebagai ilustrasi, katakanlah Anda sedang berbicara dengan seorang teman di dapur yang kebetulan juga memiliki lemari es yang sangat keras. Katakan juga bahwa kulkas menghasilkan 50 dB dengungan, anggap ini kebisingan karena membuat isinya tetap dingin. Jika teman yang Anda ajak bicara berbicara dengan suara 30 dB, anggap suara tersebut adalah sinyal. Anda tidak akan bisa mendengar sepatah kata pun karena suara kulkas mengalahkan ucapan teman Anda. Anda mungkin meminta teman Anda untuk berbicara lebih keras, tetapi bahkan pada 60 dB, Anda mungkin masih perlu meminta mereka untuk mengulanginya. Berbicara pada 90 dB mungkin tampak lebih seperti pertandingan berteriak, tetapi setidaknya kata-kata akan didengar dan dipahami \citep{Altunian2021}. Formula 2.1 merupakan rumus untuk mencari nilai SNR \citep{Kieser2005}

\begin{equation}
	\begin{aligned}
		SNR_{db}=10log_{10}(\frac{P_{signal}}{P_{noise}})
	\end{aligned}
\end{equation}

Dimana:
\newline
$P_{signal}$ 		\hspace{0.5cm}: nilai sinyal asli dalam bentuk watt \newline
$P_{noise}$ 	\hspace{0.6cm}: nilai sinyal \textit{noise} dalam bentuk watt \newline

\section{\textit{Signal Strength}}
\hspace{1,2cm}Kekuatan sinyal atau \textit{signal strength} berarti ukuran seberapa kuat sinyal transmisi yang diterima, diukur atau diprediks, pada titik referensi yang merupakan jarak  dari antena pemancar \citep{Hendrickson2022}. \textit{signal strength} umumnya berkurang dengan bertambahnya jarak \citep{Matthews2018}. Sinyal TV adalah tegangan, dB mengacu pada skala mikro-volt yang digunakan untuk implementasi sistem TV menjadi proses penambahan dan pengurangan yang sederhana. \textit{signal strength} didasarkan pada skala mikro-volt dB. Skala dimulai pada -30dBm akan menjadi mikro-Watt, -60dBm menjadi 1 nano-Watt, 0dBm yang akan menjadi 1 miliWatt, 30dBm akan menjadi 1 Watt, . \textit{signal strength} mengalami peningkatan sebanyak 30 dB per kelipatan 1000. Peningkatan tersebut menunjukkan bahwa ketika berhadapan dengan pengukuran sinyal yang lemah atau terbatas, peningkatan kecil dalam dB sering kali dapat membuat perbedaan besar \citep{Frost2014}. Tingkat kekuatan sinyal minimum yang disarankan adalah sebagai berikut \citep{Hendrickson2022}:

\begin{itemize}
	\item TV Digital Terestrial -45dB (Idealnya tidak kurang dari -50dB) <-- Cari referensinya lagi
	\item TV Analog -60dB
	\item Sinyal TV Satelit -47dB (Idealnya tidak kurang tidak -52dB)
\end{itemize}

Kualitas atau sinyal yang \textit{robust} atau kokoh diukur dalam hal kekuatan sinyal asli yang dikurangi \textit{noise} yang dapat berasal dari berbagai sumber. \textit{Noise} listrik sebenarnya akan ada di dalam sinyal, jadi inilah mengapa mengandalkan kekuatan sinyal saja tidak selalu merupakan faktor penentu kualitas sinyal yang handal. Meskipun demikian, semakin banyak sinyal yang dapat diperoleh dari pemancar TV, semakin besar perlindungan yang Anda miliki terhadap gangguan dan gangguan listrik \citep{Matthews2018}. Formula 2.2 merupakan rumus untuk mencari nilai \textit{signal strength}

\begin{equation}
	\begin{aligned}
		L_{dBm}=10log_{10}\left ( \frac{P}{0,001W} \right)
	\end{aligned}
\end{equation}

Dimana:
\newline
$L_{dBm}$ 		\hspace{0.4cm}: nilai \textit{signal strength} dalam satuan dBm \newline
$P$ 	\hspace{1cm}: nilai sinyal yang diterima oleh antena \textit{receiver} dalam satuan mW \newline

\section{Metrik Kualitas Gambar}
\hspace{1,2cm}Penilaian kualitas citra dapat diartikan sebagai menilai atau mengukur kualitas suatu citra yang sesuai atau mengacu pada citra aslinya. Gambar dalam kompresi, jika diambil terdapat distorsi yang besar maka tidak akan cocok dengan gambar asli yang disimpan dalam dataset sehingga menemukan kualitas gambar di area tersebut sangat diperlukan. \textit{image quality assessment algorithms} (IQA) merupakan salah satu proses penilaian kulaitas gambar secara objektif, algoritma tersebut akan memprediksi kualitas gambar secara objektif. Metode objektif yang dipakai adalah metode klasifikasi tanpa referensi \citep{Kumar2015}.

Metode objektif bukan satu-satunya perspektif dimana suatu gambar hanya dinilai dari sudut pandang komputer. Suatu gambar dapat dinilai dengan mata manusia sehingga mempertimbangkan figur tambahan jasa atau Pengamat dapat memberikan wawasan yang jauh lebih informatif. DAta keluaran pada gambar, secara umum dinyatakan dari metrik objektif untuk stimulus visual yang diberikan dinyatakan sebagai nilai tunggal pada suatu skala berkelanjutan. Data keluaran dengan metode objektif tersebut menunjukan bahwa ketika skor kualitas yang diprediksi pada gambar dengan nilai yang diperoleh, keunggulan kualitas tiap gambar selalu terbentuk, tidak peduli seberapa kecil perbedaannya. Perbedaan skor kualitas yang bukan bernilai nol antara dua gambar serupa dapat menyebabkan keambiguan ketika perbedaan kualitas tidak terlihat oleh Pengamat. Kepekaan visual manusia terbatas dalam arti bahwa sejumlah kecil perbedaan nilai piksel terkadang tidak dapat dibedakan secara visual tergantung pada beberapa faktor seperti pencahayaan keseluruhan dan nilai piksel \citep{Cheon2021}.  Metode penilaian subjektif biasanya digunakan untuk menghitung kualitas gambar. Penilaian subjektif ini digunakan oleh Pengamat untuk menilai kualitas gambar. Gambar diberikan kepada Pengamat. Pengamat diberikan persyaratan waktu, Pengamat tersebut memberikan skor atau nilai pada gambar. Hasil subjektif dapat memberikan hasil yang akurat \citep{Kumar2015}.

Gambar \ref{Contoh gambar dari Basis Data} menunjukkan contoh gambar yang menunjukkan adanya ambiguitas \citep{Cheon2016}. Dua gambar referensi (burung beo dan rumah) diambil dari \textit{database} Penilaian Kualitas Gambar LIVE (SANDY 18), kompresi JPEG2000 dilakukan untuk memberi \textit{noise} pada gambar dengan bitrate yang berbeda. Ketika Gambar \ref{Contoh gambar dari Basis Data}a dan \ref{Contoh gambar dari Basis Data}b dibandingkan secara visual, perbedaan kualitasnya dapat dengan mudah dibedakan. Penilaian kualitas subjektif dilakukan percobaan, dimana sebagian besar Pengamat (14 dari 15) memilih Gambar \ref{Contoh gambar dari Basis Data}b sebagai yang memiliki kualitas lebih baik. Metode objektif dengan PSNR juga menilai Gambar \ref{Contoh gambar dari Basis Data}b memiliki kualitas yang lebih baik (dengan perbedaan 2,49 dB). Perbedaan antara Gambar \ref{Contoh gambar dari Basis Data}c dan \ref{Contoh gambar dari Basis Data}d hampir tidak terlihat, hampir setengah dari Pengamat (6 dari 15) memilih Gambar \ref{Contoh gambar dari Basis Data}c. Kualitas yang diukur dengan \textit{peak signal-to-noise ratio} (PSNR) masih menentukan bahwa Gambar \ref{Contoh gambar dari Basis Data}d lebih baik. Gambar \ref{Contoh gambar dari Basis Data}d menunjukkan perbedaan sebesar 2,54 dB, yang bahkan lebih besar dari perbedaan antara Gambar \ref{Contoh gambar dari Basis Data}a dan \ref{Contoh gambar dari Basis Data}b. Hasil yang tidak konsisten antara pengukuran kualitas subjektif dan objektif tidak dapat dilakukan untuk sistem multimedia yang mengoptimalkan kualitas. Sistem yang mengandalkan PSNR mungkin mencoba memberikan Gambar \ref{Contoh gambar dari Basis Data}d daripada Gambar \ref{Contoh gambar dari Basis Data}c untuk meningkatkan QoE dengan bit yang meningkat (20 hingga 35 kbyte), yang sebenarnya tidak begitu layak bagi Pengamat.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.9\columnwidth]{bab2/Gambar/Contoh gambar dari Basis Data.jpg} 
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Contoh gambar dari Basis Data Penilaian Kualitas Gambar LIVE, yang menunjukkan ambiguitas metrik kualitas objektif (dalam hal ini, PSNR)\citep{Sheikh2006}}\label{Contoh gambar dari Basis Data}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Penilaian Kualitas Gambar Referensi Penuh}
\hspace{1,2cm}Penilaian secara objektif dapat diklasifikasikan menjadi dua jenis.  \textit{Full-reference image quality assessment (FR-IQA)} atau Penilaian kualitas referensi penuh yaitu membandingkan gambar referensi atau asli dengan gambar uji. \textit{No-reference image quality assessment} (NR-IQA) atau tidak ada penilaian kualitas referensi yang mengacu pada pemeriksaan kualitas oleh algoritma dimana hanya gambar uji (yaitu, gambar terdistorsi) yang dapat diakses \citep{Varga2021,Dihin2020}.

IQA yang sangat menjanjikan tetapi relatif kurang dipelajari digunakan sebagai tujuan untuk desain dan optimalisasi algoritma pemrosesan gambar baru. Parameter metode pemrosesan gambar biasanya disesuaikan untuk meminimalkan \textit{mean squared error} (MSE). MSE merupakan metode yang paling sederhana dari semua metode pembanding kualitas gambar, meskipun telah banyak dikritik karena korelasinya yang buruk dengan persepsi manusia tentang kualitas gambar. Upaya awal optimasi persepsi menggunakan indeks \textit{structural similarity} (SSIM) sebagai pengganti MSE untuk mencapai keuntungan persepsi dalam aplikasi restorasi gambar, streaming video nirkabel, pengkodean video dan sintesis gambar, meskipun ini belum diuji terhadap penilaian manusia \citep{Ding2021}.

\subsection{Penilaian Kualitas Gambar Tanpa Referensi}
\hspace{1,2cm}
Penilaian kualitas gambar tanpa referensi (No-Reference Image Quality Assessment, NR-IQA) adalah metode penilaian kualitas gambar yang tidak memerlukan gambar referensi untuk melakukan penilaian. penilaian kualitas gambar atau video dalam kategori ini dilakukan secara buta berdasarkan fitur yang diekstraksi dari konten multimedia yang dinilai karena tidak ada referensi yang tersedia. Evaluasi kualitas gambar dan video berbasis NR adalah tugas yang menantang karena fitur yang diekstraksi dapat memberikan informasi yang sangat terbatas.\citep{Dost2022}. 

Metode NR-IQA dapat digunakan untuk mengevaluasi kualitas gambar yang telah mengalami distorsi seperti kompresi, blur, noise, blocking artifact, dan kerusakan temporal. Dalam metode NR-IQA, tidak ada gambar referensi yang digunakan sebagai pembanding, sehingga penilaian kualitas gambar dilakukan secara independen dan tidak bergantung pada gambar referensi yang digunakan.

\subsubsection{Metrik NR-Bloking}

\textit{Blocking} muncul di semua teknik kompresi berbasis blok dan disebabkan oleh kuantisasi kasar komponen frekuensi. Artefak ini dapat diamati sebagai diskontinuitas permukaan atau tepi pada batas blok. Masalah dengan skema berbasis blok seperti JPEG adalah gambar dibagi menjadi sub-blok dengan ukuran masing-masing piksel berukuran 8x8. Transformasi dan proses kuantisasi kemudian diterapkan pada sub-blok secara individual dan independen. Korelasi antara sub-blok yang berdekatan secara spasial tidak diperhitungkan selama proses pengkodean, oleh karena itu transisi halus antara batas tepi setiap sub-blok berkurang. Selama proses decoding, batas tepi tidak dapat dipulihkan sepenuhnya seperti yang terlihat pada gambar asli. Batas blok sekarang terlihat. \textit{blockiness} atau artefak pemblokiran dapat dengan mudah diamati pada gambar seperti yang ditunjukkan pada Gambar \ref{Contoh gambar asli Lena dan versi terdistorsinya dengan artefak pemblokiran}, bahkan lebih terlihat ketika bit rate atau jumlah bit untuk mewakili gambar dikurangi \citep{Kusuma2005}.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.9\columnwidth]{bab2/Gambar/Contoh gambar asli Lena dan versi terdistorsinya dengan artefak pemblokiran.jpg}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Contoh gambar asli Lena dan versi terdistorsinya dengan artefak pemblokiran \citep{Kusuma2005}}\label{Contoh gambar asli Lena dan versi terdistorsinya dengan artefak pemblokiran}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsubsection{Metrik NR-Blur}

\textit{Blur} diamati sebagai kehalusan pada tepi atau kurangnya detail seperti yang ditunjukkan pada Gambar 4.13. Hal ini disebabkan oleh hilangnya komponen frekuensi tinggi jika dibandingkan dengan gambar aslinya. Secara matematis, gambar \textit{blur} dapat dimodelkan sebagai berikut:

\begin{equation}
	\begin{aligned}
		g(x,y)=h(x,y)*f(x,y)+n(x,y)
	\end{aligned}
\end{equation}

dimana $g(x,y)$, $f(x,y)$, dan $h(x,y)$ masing-masing mewakili gambar buram, gambar asli, dan \textit{point spread function} (PSF) atau fungsi \textit{blur}. Fungsi $n(x,y)$ menunjukkan \textit{noise} tambahan dari akuisisi citra jika ada. Simbol * adalah operator konvolusi. Artefak \textit{blur} sebagian besar terjadi pada gambar terkompresi berbasis wavelet, seperti JPEG2000. Hal ini disebabkan oleh dekomposisi multi-resolusi dari transformasi wavelet. Jika sebuah gambar sangat terkompresi, maka hanya koefisien frekuensi rendah yang dipertahankan dalam gambar terkompresi. Akibatnya, gambar kehilangan detail halus yang terkait dengan komponen frekuensi tinggi. Informasi bentuk pada dasarnya dipertahankan sementara informasi tekstur sangat diperhalus. Skema kompresi berbasis DCT seperti JPEG juga menunjukkan \textit{blur}, meskipun itu bukan artefak utama \citep{Kusuma2005}.


\subsubsection{Metrik NR-Temporal}

\textit{Frozen frame} sebagai \textit{frame} video yang identik dengan yang sebelumnya (\textit{frame repeat}) dan mendefinisikan peristiwa pembekuan sebagai satu set \textit{frozen frame} berturut-turut. Setiap peristiwa pembekuan dicirikan oleh durasi pembekuan tergantung pada jumlah \textit{frame} yang dibekukan secara berurutan dalam peristiwa itu. Total durasi pembekuan video kemudian diwakili oleh akumulasi semua durasi semua peristiwa pembekuan. Dalam contoh ilustrasi Gambar \ref{Contoh video yang terganggu oleh pembekuan frame temporal. Setiap huruf yang berbeda mewakili frame yang unik}, video referensi memiliki kecepatan \textit{frame} 25 fps. Oleh karena itu, setiap \textit{frame} unik memiliki durasi 40 ms. Video yang terdegradasi berisi tiga peristiwa pembekuan, dengan total sepuluh \textit{frozen frame}. Setiap \textit{frame} yang dibekukan memiliki durasi 40 ms dan ketiga peristiwa pembekuan memiliki durasi masing-masing 80, 120 dan 200 ms. Total durasi pembekuan dalam video adalah 400 ms.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.9\columnwidth]{bab2/Gambar/Contoh video yang terganggu oleh pembekuan frame temporal. Setiap huruf yang berbeda mewakili frame yang unik.jpg}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Contoh video yang terganggu oleh pembekuan frame temporal. Setiap huruf yang berbeda mewakili frame yang unik. \citep{Quan_Huynh_Thu_2009}}\label{Contoh video yang terganggu oleh pembekuan frame temporal. Setiap huruf yang berbeda mewakili frame yang unik}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Pendekatan tanpa referensi, identifikasi \textit{frozen frame} harus dilakukan hanya dengan menggunakan urutan yang diproses karena akses ke referensi tidak dimungkinkan. Kasus pendekatan tanpa referensi, tidak mungkin untuk membedakan konten diam (yaitu konten yang sengaja tidak bergerak) dari \textit{frozen frame} (yaitu konten yang tidak bergerak sebagai akibat dari gangguan video). Pendekatan umum untuk mendeteksi \textit{frozen frame} adalah dengan menghitung \textit{mean-squared error} (MSE) antara \textit{frame} saat ini dan sebelumnya dan mempertimbangkan \textit{frame} saat ini untuk dibekukan jika MSE sama dengan nol \citep{Quan_Huynh_Thu_2009}.

\subsection{\textit{Artificial Neural Network} (ANN)}
\hspace{1,2cm} ANN diterapkan dalam prediksi berbagai proses. JST telah berhasil diterapkan di berbagai bidang matematika, teknik, kedokteran, ekonomi, neurologi. ANN dapat didefinisikan sebagai jaringan yang kompleks, yang terdiri dari unit pemrosesan dasar yang saling berhubungan yang disebut neuron. ANN dapat ditentukan oleh tiga faktor yaitu; Struktur, Algoritma pembelajaran, dan fungsi aktivasi (SANDY 26).Aplikasi ANN dapat dievaluasi sehubungan dengan faktor analisis data seperti akurasi, kecepatan pemrosesan, latensi, kinerja, toleransi kesalahan, volume, skalabilitas, dan konvergensi. Potensi besar ANN adalah pemrosesan berkecepatan tinggi yang disediakan dalam implementasi paralel besar-besaran dan ini telah meningkatkan kebutuhan untuk penelitian dalam domain ini. ANN dapat dikembangkan dan digunakan untuk pengenalan gambar, pemrosesan bahasa alami dan sebagainya. Saat ini, ANN banyak digunakan untuk pendekatan fungsi universal dalam paradigma numerik karena sifat yang sangat baik dari belajar mandiri, adaptif, toleransi kesalahan, nonlinier, dan kemajuan input ke pemetaan output (SANDY 24).

Gambar \ref{Struktur otak manusia dengan kemampuan operasional} adalah demonstrasi koneksi di dalam otak yang bekerja seperti jaringan saraf yang melakukan fungsi penalaran kecerdasan. Brainstorming untuk memahami suatu skenario (seperti platform pencarian web internet), mengenali ucapan (misalnya dari orang yang dikenal dan orang yang tidak dikenal) seperti otak manusia, mengenali gambar (dari suatu objek) seperti otak, dapat memproses bahasa (menerjemahkan bahasa) seperti yang dilakukan otak manusia dan dapat melakukan hal-hal lain seperti makan, mengendarai sepeda (intuisi diri). ANN melihat penggunaan besar-besaran dalam domain tertentu, seperti diagnosis hepatitis, pengenalan suara, pemulihan data dalam telekomunikasi dari perangkat lunak yang rusak, interpretasi pesan multi-bahasa, pengenalan objek tiga dimensi, analisis tekstur, pengenalan wajah, deteksi ranjau bawah laut, dan pengenalan kata tulisan tangan. ANN dapat belajar dengan contoh seperti orang. Dalam beberapa kasus, ANN dapat dirancang untuk aplikasi tertentu seperti klasifikasi data atau pengenalan pola melalui proses pembelajaran. Pembelajaran di otak manusia memerlukan penyesuaian hubungan sinaptik antara dan antar neuron, demikian juga pembelajaran di ANN. Secara umum, ANN berfungsi seperti tiruan dari otak manusia (SANDY 24).

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.9\columnwidth]{bab2/Gambar/Struktur otak manusia dengan kemampuan operasional.jpg}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Struktur otak manusia dengan kemampuan operasional (SANDY 24)}\label{Struktur otak manusia dengan kemampuan operasional}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Data masukan pada ANN akan diberikan pada setiap masukan bobot, yang bisa berupa angka positif atau negatif. Sebuah input dengan bobot positif yang besar atau bobot negatif yang besar, akan memiliki pengaruh yang kuat terhadap output neuron. Sebelum dimulai, ANN harus menetapkan setiap bobot ke nomor acak, kemudian memulai proses pelatihan.

\begin{enumerate}
	\item Ambil input dari contoh set pelatihan, sesuaikan dengan bobot, dan berikan melalui formula khusus untuk menghitung output neuron. 
	\item 	Hitung error, yang merupakan selisih antara output neuron dan output yang diinginkan dalam contoh set pelatihan. 
	\item Bergantung pada arah kesalahan, sesuaikan bobotnya sedikit.
	\item Ulangi proses ini 10.000 kali.
\end{enumerate}

Akhirnya bobot neuron akan mencapai optimal untuk set pelatihan. Jika pengguna membiarkan neuron berpikir tentang situasi baru dengan mengikuti pola yang sama, itu akan membuat prediksi yang baik (SANDY 25). Gambar \ref{Langkah training ANN} merupakan gambaran \textit{training} pada ANN. formula 2.4 merupakan rumus dari jumlah bobot dari data masukan neuron. 

\begin{equation}
	\begin{aligned}
		\sum w_{i}.x_{i}=w_{i}._{1}+w_{2}.x_{2}+....+w_{n}.x_{n}
	\end{aligned}
\end{equation}

Dimana:
\newline
$\sum w_{i}.x_{i}$ 		\hspace{0.4cm}: data keluaran \newline
$w_{i}$ 	\hspace{1.3cm}: bobot \newline
$x_{i}$ 	\hspace{1.4cm}: data masukan \newline

Hasil dari data keluaran tersebut dinormalisasi sehingga hasilnya antara 0 dan 1. Normalisasi tersebut menggunakan fungsi yang sesuai secara matematis yang disebut fungsi Sigmoid.

\begin{equation}
 	\begin{aligned}
 		\frac{1}{1+e^{-x}}
 	\end{aligned}
\end{equation}


Fungsi Sigmoid jika diplot pada grafik, fungsi Sigmoid menggambar kurva berbentuk S yang ditunjukkan pada gambar \ref{Fungsi Sigmoid}. Jadi dengan mensubstitusi formula 2.4 ke formula 2.5. Rumus akhir untuk keluaran neuron ditunjukkan pada formula 2.6, dimana y adalah data keluaran neuron

\begin{equation}
	\begin{aligned}
		y = Data Keluaran Neuron = \frac{1}{1+e^{-(\sum w_{i}.x_{i})}}
	\end{aligned}
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.9\columnwidth]{bab2/Gambar/Fungsi Sigmoid.jpg}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Fungsi Sigmoid}\label{Fungsi Sigmoid}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Gambar \ref{Langkah training ANN} terdapat penyesuaian bobot. Peneyesuaian bobot tersebut dapat menggunakan rumus \textit{Error Weighted Derivative} yang ditunjukkan pada formula 2.7.

\begin{equation}
	\begin{aligned}
		Penyesuaian Bobot = Error.Input.SigmoidCurveGradient(y)
	\end{aligned}
\end{equation}

Dimana:
\newline
$error$ 		\hspace{0.4cm}: data keluaran - data keluaran asli \newline
$input$ 	\hspace{0.4cm}: data terukur \newline

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=0.9\columnwidth]{bab2/Gambar/Langkah training ANN.jpg}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Langkah training ANN (SANDY 25)}\label{Langkah training ANN}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Tujuan dari formula 2.7 adalah membuat penyesuaian proporsional dengan ukuran kesalahan. Kalikan dengan data masukannya, yaitu 0 atau  1. Jika data masukannya 0, bobotnya tidak disesuaikan. Kalikan dengan gradien kurva Sigmoid (Gambar \ref{Fungsi Sigmoid}) untuk langkah selanjutnya. Berikut adalah langkah-langkah dari perhitungan formula 2.7

\begin{enumerate}
	\item Menggunakan kurva Sigmoid untuk menghitung data keluaran dari neuron
	\item Jika data keluarannya adalah angka positif atau negatif yang besar, itu menandakan neuron cukup percaya diri dengan satu atau lain cara.
	\item Dari gambar \ref{Fungsi Sigmoid}, kita dapat melihat bahwa pada bilangan besar, kurva Sigmoid memiliki gradien yang dangkal.
	\item Jika neuron yakin bahwa bobot yang ada benar, neuron tidak ingin terlalu banyak menyesuaikannya. Mengalikan dengan gradien kurva Sigmoid dapat mencapai bobot yang benar.
\end{enumerate}

Gradien kurva Sigmoid, dapat ditemukan dengan mengambil turunan:

\begin{equation}
	\begin{aligned}
		SigmoidCurveGradient(y)=y.(1-y)
	\end{aligned}
\end{equation}

Jadi dengan memasukkan forluma 2.8 ke formula 2.7, rumus akhir untuk menyesuaikan bobot adalah:

\begin{equation}
	\begin{aligned}
		Penyesuaian Bobot = Error.input.y.(1-y)
	\end{aligned}
\end{equation}


\section{Perangkat Lunak \textit{tvheadend}}
Tvheadend adalah aplikasi server TV streaming yang open-source dan gratis. Aplikasi ini memungkinkan pengguna untuk menonton TV langsung dari komputer atau perangkat lain melalui jaringan. Tvheadend dapat digunakan dengan berbagai jenis perangkat lunak client, termasuk Kodi, VLC, dan banyak lagi. Tvheadend mendukung berbagai jenis tunner TV dan format pemrosesan video. Aplikasi ini juga menyediakan berbagai fitur, seperti merekam dan menunda TV langsung, dan memungkinkan pengguna untuk mengatur saluran dan membuat daftar putar. Tvheadend tersedia untuk berbagai platform, termasuk Linux, macOS, dan Windows \citep{tvheadend2015}.

%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
	\vspace{-0.1cm}
	%\rule{\columnwidth}{0.1pt}
	\begin{center}
		\includegraphics[width=1\columnwidth]{bab2/Gambar/tvheadend.png}
	\end{center}
	\vspace{-0.2cm}
	%\rule{\columnwidth}{0.1pt}
	\caption{Antarmuka \textit{website} perangkat lunak \textit{tvheadend}}\label{TVHeadend}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%% GAMBAR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

TVHeadend digunakan untuk menangkap, mengakses, dan mengelola sinyal TV dan radio yang disiarkan melalui antena, satelit, dan kabel. Fungsi utama TVHeadend adalah sebagai server TV yang memungkinkan pengguna untuk menonton dan merekam program TV dan radio melalui jaringan lokal atau internet. TVHeadend juga menyediakan fitur EPG (Electronic Program Guide) untuk memberikan informasi tentang jadwal program dan fitur PVR (Personal Video Recorder) untuk merekam dan menyimpan program TV seperti yang ditunjukkan pada gambar \ref{TVHeadend}. Selain itu, TVHeadend dapat diintegrasikan dengan beberapa perangkat lunak media center seperti Kodi dan Plex untuk menyediakan pengalaman media center yang lebih lengkap \citep{Emmet2022}.


\section{\textit{Subjective Assessment}}
\hspace{1.2cm}
Metodologi untuk penilaian subyektif kualitas gambar televisi ITU-R adalah seperangkat prosedur dan pedoman yang digunakan untuk melakukan penilaian kualitas gambar televisi dengan melibatkan orang-orang sebagai penilai. Pedoman ini dikembangkan oleh International Telecommunication Union-Radiocommunication Sector (ITU-R) dan digunakan secara luas oleh industri penyiaran dan penyedia layanan televisi untuk mengevaluasi kualitas gambar televisi mereka. Penilaian subyektif kualitas gambar televisi dapat memberikan umpan balik yang berharga tentang bagaimana kualitas gambar tersebut diterima oleh penonton dan membantu penyedia layanan meningkatkan kualitas gambar mereka \citep{Rodriguez2014}.

Pada penelitian ini digunakan standar pengukuran subyektif ITU-R BT.500-14 yang merupakan seperangkat pedoman dan prosedur untuk penilaian subyektif kualitas gambar televisi. Pedoman tersebut  menyediakan metode standar untuk mengevaluasi kualitas gambar televisi secara konsisten dan dapat diulang. Standar tersebut banyak digunakan dalam industri penyiaran dan telekomunikasi untuk memastikan bahwa gambar televisi memenuhi tingkat kualitas tertentu. Pada standar tersebut juga mendefinisikan beberapa metode penilaian subyektif yang berbeda. Metode-metode ini dirancang untuk mengevaluasi berbagai aspek kualitas gambar, seperti resolusi, akurasi warna, dan visibilitas artefak \citep{IRB2019}. Beberapa metode yang terdapat pada standar tersebut diantaranya:

\begin{enumerate}
	\item Double-stimulus impairment scale (DSIS). 
	
		Metode ini melibatkan dua gambar atau video yang ditampilkan secara bergantian di layar, yaitu gambar atau video referensi yang dianggap berkualitas tinggi dan gambar atau video uji yang mengalami gangguan atau distorsi tertentu. Panelis diminta untuk memberikan skor kualitas pada gambar atau video uji berdasarkan seberapa besar gangguan atau distorsi yang mereka rasakan dibandingkan dengan gambar atau video referensi. Metode DSIS memiliki keuntungan dalam mengurangi efek bias atau kecenderungan panelis dalam memberikan skor kualitas karena panelis harus membandingkan gambar atau video uji dengan gambar atau video referensi yang dianggap berkualitas tinggi. Namun, metode ini dapat memakan waktu yang lebih lama karena panelis harus melihat dua gambar atau video secara bergantian dan memberikan skor kualitas untuk setiap gambar atau video uji.
	
	\item Single Stimulus (SS)
	
		Metode Single-stimulus (SS) adalah metode subjektif dalam penilaian kualitas citra atau video di mana penonton diberi satu citra atau video pada setiap waktu dan diminta untuk memberikan nilai kualitas. Penonton memberikan nilai kualitas pada skala tertentu, seperti skala MOS (Mean Opinion Score) yang berkisar dari 1 hingga 5 atau 1 hingga 10, di mana nilai yang lebih tinggi menunjukkan kualitas yang lebih baik. Metode SS terdiri dari beberapa varian, seperti Single Stimulus Continuous Quality Evaluation (SSCQE) dan Absolute Category Rating (ACR). Metode SS sering digunakan untuk penilaian kualitas video pada televisi dan perangkat seluler.
		
		
	\item Single Stimulus Continuous Quality Evaluation (SSCQE) 
	
		Metode penilaian subyektif dalam penilaian kualitas gambar atau video. Dalam metode ini, penilai diberikan tampilan gambar atau video tunggal untuk dinilai secara terus menerus tanpa adanya perbandingan dengan tampilan gambar atau video lainnya. Penilai diminta memberikan penilaian kontinu pada kualitas gambar atau video yang mereka lihat menggunakan skala penilaian dari sangat buruk hingga sangat baik. Metode ini dapat digunakan untuk mengukur kualitas gambar atau video pada aspek-aspek tertentu seperti kecerahan, kontras, ketajaman, atau aspek lainnya.
		
		\item Simultaneous Double Stimulus for cCntinuous Evaluation (SDSC) 
		
		Metode subyektif untuk mengevaluasi kualitas gambar televisi. Metode ini melibatkan pemutaran dua sumber video secara bersamaan, yaitu sumber video referensi dan sumber video yang diuji. Penonton kemudian diminta untuk menilai kualitas video yang diuji dengan cara memberikan nilai pada skala kualitas yang berkelanjutan pada layar monitor, sementara video referensi tetap diputar. Metode SDSC memungkinkan penonton untuk membandingkan kualitas gambar dari dua sumber video secara langsung, sehingga dapat memberikan penilaian yang lebih akurat dan objektif terhadap kualitas gambar televisi. 
\end{enumerate}

Standar ITU-R BT.500 juga memberikan panduan tentang bagaimana memilih dan melatih panel penonton untuk penilaian kualitas subyektif. Ini menjelaskan kualifikasi yang diperlukan untuk panelis, jumlah panelis yang dibutuhkan, dan proses pelatihan untuk memastikan bahwa panelis konsisten dan dapat diandalkan dalam penilaian mereka. Secara keseluruhan, standar ITU-R BT.500 menyediakan kerangka kerja yang komprehensif untuk penilaian subyektif kualitas gambar televisi, yang penting untuk memastikan bahwa penonton menerima pengalaman menonton berkualitas tinggi \citep{Mart_nez_Rach_2014}.

\subsection{Raspberry Pi + TV Hat}
\subsection{DVB-T2 TV Tunner}


\subsection{\textit{Confusion Matrix}}
\hspace{1.2cm}
\textit{Confusion matrix }adalah tabel evaluasi performa model yang digunakan untuk menunjukkan jumlah prediksi benar dan salah yang dibuat oleh model pada data uji. Tabel ini digunakan untuk menghitung akurasi, presisi, dan recall dengan membandingkan hasil prediksi model dengan nilai sebenarnya dari data uji. Confusion matrix digunakan pada tugas klasifikasi dengan dua kelas target dan terdiri dari empat kemungkinan hasil: true positive, false positive, true negative, dan false negative.

\textit{Multiple class confusion matrix} adalah bentuk tabel evaluasi performa model yang digunakan untuk mengevaluasi performa model pada data uji dengan lebih dari dua kelas target. Tabel ini terdiri dari baris dan kolom, di mana setiap baris dan kolom mewakili kelas target dan prediksi yang berbeda. Diagonal matriks ini menunjukkan jumlah prediksi benar, sementara sel di luar diagonal menunjukkan jumlah prediksi salah. Multiple class confusion matrix digunakan untuk menghitung akurasi, presisi, dan recall pada setiap kelas target, serta metrik evaluasi lainnya seperti F1 score. Metrik evaluasi ini berguna dalam mengevaluasi performa model pada tugas klasifikasi dengan lebih dari dua kelas target.

Akurasi dan presisi adalah dua metrik yang digunakan untuk mengukur kinerja model dalam klasifikasi, termasuk dalam konteks matriks kebingungan multi-kelas (MCCM). Berikut adalah perbedaan antara keduanya:

Akurasi:
Akurasi adalah ukuran kinerja yang menggambarkan seberapa baik model klasifikasi memprediksi kelas yang benar. Dalam konteks MCCM, akurasi dihitung dengan mengambil jumlah prediksi yang benar (nilai pada diagonal utama matriks) dibagi dengan jumlah total prediksi (semua elemen dalam matriks). Akurasi mencakup semua kelas dan memberikan gambaran umum tentang seberapa baik model bekerja.

Presisi:
Presisi adalah ukuran kinerja yang menggambarkan seberapa baik model klasifikasi mengidentifikasi hasil positif yang benar dari keseluruhan hasil positif yang diprediksi. Dalam konteks MCCM, presisi dihitung untuk setiap kelas secara terpisah menggunakan rumus: Presisi = TP / (TP + FP), di mana TP (True Positives) dan FP (False Positives) dihitung dari matriks kebingungan. Kemudian, presisi untuk setiap kelas digabungkan menggunakan metode seperti rata-rata tertimbang berdasarkan jumlah sampel per kelas, rata-rata sederhana (macro-average), atau micro-average.

Perbedaan utama antara akurasi dan presisi adalah fokus pada keseluruhan kinerja model (akurasi) vs. kinerja model dalam mengidentifikasi hasil positif yang benar (presisi). Akurasi memberikan gambaran umum tentang seberapa baik model memprediksi kelas yang benar, sedangkan presisi menyoroti kinerja model dalam mengidentifikasi hasil positif yang benar untuk setiap kelas. Presisi sangat berguna dalam kasus di mana false positives memiliki konsekuensi yang lebih tinggi, seperti dalam diagnosis medis atau deteksi spam.

%%%%%%%%%%%%%%%%%%%% ALGORITMA DAN PESUDO-CODE %%%%%%%%%%%%%%%%%%%%
%\begin{algorithm}
%\caption{MAX Finds the Maximum Number}
%	\begin{flushleft}
%	\textbf{INPUT:} \textbf{finite set $A=\{a_1, a_2, \ldots, a_n\}$ of integers}\\
%	\textbf{OUTPUT:}	\textbf{The largest element in the set}
%		\end{flushleft}
%	
%		\begin{algorithmic}[1]
%\State	$max \gets a_1$\;
%\NoNumber{ \qquad  \For{$i \gets 2$ \textbf{to} $n$} \{ }
%\NoNumber{\qquad \If{$a_i > max$} \{ }
%\NoNumber{\qquad $max \gets a_i$\;}
%\NoNumber{\qquad \} }
%\NoNumber{ \} }
%\NoNumber{	\Return{$max$}\;}
%	\end{algorithmic}
%\end{algorithm}
%%%%%%%%%%%%%%%%%%%% ALGORITMA DAN PESUDO-CODE %%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%% ALGORITMA DAN PESUDO-CODE %%%%%%%%%%%%%%%%%%%%
%\begin{algorithm}
%	\caption{MAX Finds the Maximum Number}
%	\begin{flushleft}
%		\textbf{INPUT:} \textbf{gambar RGB}\\
%		\textbf{OUTPUT:}	\textbf{nilai pengukuran blok}
%	\end{flushleft}
%	
%	\begin{algorithmic}[1]
%		\Procedure{BlockMetric}{$im_path$}
%		\State $imgInput \gets \text{read image from }im_{path}$
%		\State $M, N, c \gets \text{get size of image }imgInput$
%		
%		\qquad \If {$c == 3$}
%		\State $targetImage \gets \text{convert image to grayscale}$
%		\EndIf
%
%		\State $x \gets \text{convert targetImage to numpy array}$\\
%		\#Menghitung fitur horizontal\; \Comment{}
%		\State $d_h \gets x[:, 1:(N)] - x[:, 0:(N-1)]$ 		
%		\State $B_h \gets \text{mean}\left(\left|\left| d_h[:, 7:8*(\text{floor}(N/8)-1):8]\right|\right|\right)$
%		\State $A_h \gets (8*\text{mean}\left(\left|\left|d_h\right|\right|\right)-B_h)/7$
%		\State $sig_h \gets \text{sign}\left(d_h\right)$
%		\State $left_{sig} \gets sig_h[:, 0:(N-2)]$
%		\State $right_{sig} \gets sig_h[:, 1:(N-1)]$
%		\State $Z_h \gets \text{mean}\left(\left(left_sigright_sig\right) < 0\right)$\\
%		\#Menghitung fitur horizontal\;
%		\State $d_v \gets x[1:M, :] - x[0:(M-1), :]$
%		\State $B_v \gets \text{mean}\left(\left|\left| d_v[7:8(\text{floor}(N/8)-1):8, :]\right|\right|\right)$
%		\State $A_v \gets (8*\text{mean}\left(\left|\left|d_v\right|\right|\right)-B_v)/7$
%		\State $sig_v \gets \text{sign}\left(d_v\right)$
%		\State $up_{sig} \gets sig_v[0:(M-2), :]$
%		\State $down_{sig} \gets sig_v[1:(M-1), :]$
%		\State $Z_v \gets \text{mean}\left(\left(up_sigdown_sig\right) < 0\right)$\\
%		\#Menghitung fitur gabungan\;
%		\State $B \gets (B_h + B_v)/2$
%		\State $A \gets (A_h + A_v)/2$
%		\State $Z \gets (Z_h + Z_v)/2$\\
%		\#Menghitung fitur gabungan kualitas\;
%		\State $score \gets \alpha + \beta\left(\left(B^{\gamma_1/10000}\right) \cdot \left(A^{\gamma_2/10000}\right)\cdot\left(Z^{\gamma_3/10000}\right)\right)$
%		
%		\If {$\text{isNaN}\left(score\right)$}
%		\State $vq \gets 0$
%		\Else
%		\State $vq \gets \text{round}\left(score\times10\right)$
%		\EndIf
%		
%		\If {$vq > 100$}
%		\State $vq \gets 100$
%		\ElsIf {$vq < 0$}
%		\State $vq \gets 0$
%		\EndIf
%		\EndProcedure
%
%		
%	\end{algorithmic}
%\end{algorithm}
%%%%%%%%%%%%%%%%%%% ALGORITMA DAN PESUDO-CODE %%%%%%%%%%%%%%%%%%%%

